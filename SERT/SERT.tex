\documentclass[18px]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}

\begin{document}
\tableofcontents
\section{Schedulabilità di algoritmi a priorità fissa}
Algoritmi a priorità dinamica, come EDF, sono ottimali (sotto determinate condizioni): se $\exists$ schedulazione fattibile $\Rightarrow$ anche EDF trova schedulazione.\\ Nessun algoritmo X a priorità fissa può avere un fatto di utilizzazione U$_{X}$ = 1, deve per forza essere $<$ 1.\\ Inoltre RM è ottimale (in senso assoluto, ovvero può raggiungere U = 1) per sistemi armonici con scadenze implicite.\\ In questa condizione RM è tanto buono quanto EDF.\\ DM è ottimale tra gli algoritmi a priorità fissa, ma non in senso assoluto: se $\exists$ algoritmo a priorità fissa che trova una schedulazione fattibile per un insieme di task, allora lo fa anche DM. Questo mi fa capire assegnare priorità fisse ai task,in modo arbitrario, non fa guadagnare nulla rispetto ad assegnarle con un parametro come la scadenza relativa. Algoritmo è altrettanto buono, se non più buono di algoritmi che fissano le scadenze in modo soggettivo, posso realizzare sistemi di task basati su parametri oggettivi e non soggettivi.\\ Corollario: RM è ottimale tra gli algoritmi a priorità fissa per sistemi ti task con scadenza proporzionale al periodo.\\ Mi pongo un problema generale: se ho sys di task generale ed un algoritmo di schedulazione a priorità fissa, come faccio a verificare il sistema, ovvero a certificare che l'algoritmo produrrà sempre una schedulazione valida?
\subsection{Istanti critici}
Istanti critici: suppongo che nel sys di task tutti i job abbiano un tempo di risposta piccolo, ovvero ogni job termina prima del rilascio del job successivo del task $\Rightarrow$ ogni job viene rilasciato in un periodo e si conclude entro quel periodo (job potrebbe non rispettare la scadenza, se questa è minore del periodo).\\ L'istante critico è il momento in cui il rilascio del job comporta il massimo tempo di risposta possibile  per quel job.\\ Se almeno un job T$_{i}$ non rispetta la scadenza relativa, l'istante critico è un momento in cui il rilascio di un job provoca il mancato rispetto della scadenza di quel job.\\ Io voglio verificare che tutti i job rispettino le scadenze, sottigliezza della definizione è irrilevante dal punto di vista critico.\\ Teorema: Se ho un sistema di task a priorità fissa e tempi di risposta piccoli, l'istante in cui uno dei job di T$_{i}$  viene rilasciato contemporaneamente ai job di tutti i task con priorità maggiore di T$_{i}$ è l'istante critico di T$_{i}$.\\ Teorema non da condizione necessaria e sufficiente, ma solo sufficiente: se capita tale condizione $\Rightarrow$ ho un istante critico, ma potrei averne altri.\\ esempio : T$_{1}$=(2, 0.6) T$_{2}$=(2.5,0.2), T$_{3}$=(3,1.2).\\ T$_{1}$ ha la priorità massima: tutti i multipli di 2 sono istanti critici.\\ T$_{2}$ ha istanti critici 0 e 10, che sono anche i momenti in cui rilascio job di T$_{1}$, non c'è nessun altro momento in cui c'è rilascio contemporaneo di job di T$_{1}$ e T$_{2}$.\\ T$_{3}$ avrà rilasci in 0, 3, 6, 9: in 0 ho istante critico, 6 e 9 sono critici ma il thm non li evidenzia.\\
\includegraphics[scale=0.2]{images/SERT1710.png}\\
Stesso esempio anche se i task non sono in fase: 6 è istante critico, è descritto dal teorema.\\ Quando c'è rilascio in fase, siccome priorità è fissa, la schedulazione prodotta risulta identica a qualsiasi schedulazione non in fase $\Rightarrow$ mi interessa ricondurmi a quando tutti i task sono in fase.
\subsection{Schedulabilità per priorità fissa e tempi di risposta piccoli}Supponiamo che in un sistema ho task a priorità fissa e tempi di risposta piccoli.\\ Ordino i task per priorità decrescente, suppongo siano in fase all'istante t$_{0}$.\\ Ho i task T$_{1}$......T$_{i}$ e mi chiedo il tempo necessario per eseguire tutti i job dei task T$_{1}$......T$_{i}$, nell'intervallo [t$_{0}$, t$_{0}$+t] (t $\leq$ p$_{i}$:\\
w$_{i}$(t) = e$_{i}$ +  $\sum\limits_{k=0}^{i-1} \lceil\frac{t}{p_{k}}\rceil \cdot e_{k}$.\\ Somma si estende su tutti i task di priorità superiore di T$_{i}$, devo considerarli perché portano via tempo al job di T$_{i}$. Prendo k-esimo task: a t$_{0}$ tutti i task sono in fase, quindi rilascio sicuro un job, quando ne rilascio? Prendo il ceil di $\frac{t}{p_{k}}$,anche job rilasciato nel periodo dopo quello considerato mi ruba tempo; moltiplico tutto per e$_{k}$, il tempo che ci metto per completare i job.\\ Test di schedulabilità: dati job T$_{1}$......T$_{i}$, in fase a t$_{0}$ con priorità decrescenti con T$_{1}$......T$_{i-1}$ effettivamente schedulabili. Il task T$_{i}$ può essere schedulato nell'intervallo di tempo [t$_{0}$, t$_{0}$+D] se $\exists$ t $\leq$ D$_{i}$ tale che w$_{i}$(t) $\leq$ t. IL mio scopo è sempre quello di verificare la schedulabilità del sistema, se ne trovo uno non schedulabile la mia analisi è finita, non ci faccio nulla col sistema di task.\\ Applicazione: ho T$_{1}$......T$_{n}$ con priorità decrescenti. \\Considero un task alla volta: $\forall$ task T$_{i}$  calcolo il valore della funzione di tempo necessario w$_{i}$(t) per tutti i valori t $\leq$D$_{i}$ tali per cui t è un multiplo intero di p$_{k}$ per k $\in$ \{1,2....,i \}.Funzione w$_{i}$(t) sale a gradini, devo considerare valori per cui tale funzione cambia valori.\\ Se per almeno uno dei valori t vale che w$_{i}$(t) $\leq$ t allora T$_{i}$ è effettivamente schedulabile. Altrimenti il test fallisce, ovvero n job di T$_{i}$ potrebbe mancare la scadenza, ovvero la manca sicuro se c'è un rilascio di tutti i job in fase dei task di priorità superiore e tutti quei task hanno un tempo di esecuzione pari al loro worst-case.\\ Possono esserci casi fortuiti, quindi in ipotesi rilassate il test non conferma schedulabilità ma scheduler riesce, però il risultato non è rilevante.\\Tanto vale fermarsi e riprogettare il sistema.\\
esempio: T$_{1}$=(3,1), T$_{2}$=(5,1.5), T$_{3}$=(7, 1.25), T$_{4}$=(9,0,5) e considero le funzioni di tempo necessario:\\
\includegraphics[scale=0.3]{images/SERT1710_1.png}\\
Grafico per l'esempio precedente, ho la bisettrice del 1° quadrante, dire che w$_{i}$(t) è $\leq$ t vuol dire che w$_{i}$(t) sta sotto la bisettrice. La funzione è a scalini, non ha senso calcolarla, la applico nel periodo tra 0 e la fine del periodo.In T$_{2}$ la funzione sale sopra la bisettrice, ma non è importante: devo verificare che sia sotto in un certo momento, se fosse sempre sopra non sarebbe schedulabile.\\ Ogni volta che c'è rilascio di un task a priorità superiore $\Rightarrow$ ho gradino nella funzione di tempo necessario.\\
\includegraphics[scale=0.2]{images/SERT1710_2.png}\\
\subsection{Massimo tempo di risposta}
Massimo tempo di risposta W$_{i}$ di T$_{i}$ è il più piccolo valore prima della scadenza relativa t.c : t=w$_{i}$(t). Se l'equazione non ha soluzioni $\leq$ a D$_{i}$, allora qualche job di T$_{i}$ mancherà la scadenza relativa.\\ Uso un algoritmo:\\
\begin{itemize}
\item $t^(1)$ = e$_{1}$ in prima approssimazione
\item  Sostituisco nella funzione ed ottengo un nuovo valore $t^(k+1)$ = w$_{i}$($t^(k)$)
\item continuo ad iterare finché: 
\begin{itemize}
\item $t^(k+1)$ = $t^(k)$ e $t^(k)$ $\leq$ D$_{i}$ $\Rightarrow$ W$_{i}$ = $t^(k)$
\item $t^(k)$ $\geq$ D$_{i}$ e allora sono fuori scadenza
\end{itemize}
\end{itemize}
Ma dato che caso peggiore sono task in fase e dato che ho tutti i parametri sono noti, non sarebbe più facile provare a simulare la schedulazione? Sì, ma ci sono dei fattori che non ho considerato e che mi impediscono di simulare, esempio:
\begin{itemize}
\item Non è possibile determinare facilmente il worst case
\item Il worst case cambia da task a task
\item È difficile integrare nella simulazione altri fattori che possono essere considerati estendendo il test di schedulabilità.
\end{itemize}
In ogni caso, sia simulare il test che il test di schedulabilità stesso hanno la stessa complessità.
\subsubsection{Task periodici con tempi di risposta arbitrari}
Considero ora task con tempi di risposta arbitrari, che implica che: 
\begin{itemize}
\item Un job non deve necessariamente prima che il job successivo dello stesso task sia eseguito
\item è possibile che D$_{i}$ $\geq$ di p$_{i}$
\item Ci possono essere nello stesso istante più job di uno stesso task in attesa di essere eseguiti.
\item Un job rilasciato contemporaneamente a tutti i job dei task con priorità maggiore non ha necessariamente il massimo t. di risposta possibile.
\end{itemize}
Assumo sempre che i job di uno stesso task hanno vincoli di precedenza impliciti fra di loro, ovvero sempre eseguiti FIFO.\\ Analizzo task per task: considero T$_{i}$ (i precedenti sono schedulabili). Ho insieme task $\tau_{i}$=T$_{1}$....T$_{i}$ con priorità decrescente. \\Definisco un intervallo totalmente occupato di un livello $\pi_{i}$ un intervallo (t$_{0}$, t$_{1}$] tale che:
\begin{itemize}
\item all'istante t$_{0}$ tutti i job di $\tau_{i}$ rilasciatiti prima di t$_{0}$ sono stati completati
\item All'istante t$_{0}$ un job di $\tau_{i}$ viene rilasciato.
\item L'istante t$_{1}$ è il primo istante in cui tutti i job di $\tau_{i}$ rilasciati a partire da t$_{0}$ sono stati completati
\end{itemize}
È possibile che in un intervallo totalmente occupato il processore sia idle o esegua task non di $\tau_{i}$? No: se fosse idle, l'intervallo terminerebbe prima, non può neanche eseguire task di priorità inferiore, quindi non può eseguire task al di fuori di $\tau_{i}$\\
esempio: T$_{1}$, T$_{2}$, T$_{3}$.\\ Intervalli di T$_{3}$ non sono lunghi uguale, questo perché i rilasci di T$_{3}$ non sono in concomitanza con T$_{1}$ e T$_{2}$, posso dire che l'intervallo a lunghezza massimo quando i rilasci di tutti i task sono in fase.\\ Test di schedulabilità generale per tempi di risposta arbitrari è ancora basato sul caso peggiore, la differenza rispetto al test per tempi piccoli è che il primo job rilasciato contemporaneamente agli altri potrebbe non avereil massimo tempo di risposta.\\ Idea : $\forall$ T$_{i}$ analizzo tutti i suoi job eseguiti nel primo intervallo totalmente occupato di livello $\pi_{i}$. \\ Come determino l'intervallo totalmente occupato: 
\begin{itemize}
\item Inizio determinato dal rilascio dei primi job (in fase) dei task $\tau_{i}$=\{T$_{1}$, ...., T$_{i}$\}
\item Lunghezza massima calcolata risolvendo iterativamente t = $\sum\limits_{k=1}^{i}\lceil\frac{t}{p_{k}}\rceil \cdot e_{k}$. Molto simile alla funzione di tempo necessario, dico che aumento t fino a che non trovo il valore dato dalla sommatoria, ovvero il primo t per cui il lavoro necessario per compiere tutti i task permette di eseguire tutti i task rilasciati nell'intervallo [t$_{0}$, t$_{0}$+t] 
\end{itemize}
Quindi si procede nel seguente modo:
\begin{itemize}
\item Considero i task \{T$_{1}$, ...., T$_{i}$\} con priorità $\pi_{1}$ $<$ $\pi_{2}$....$<$ $\pi_{i}$, considero un task T$_{i}$ alla volta cominciando da quello con la massima priorità, ovvero T$_{1}$
\item Il caso peggiore per la schedulabilità di T$_{i}$: assumere che i task $\tau$ $_{i}$ = \{T$_{1}$, ...., T$_{i}$\} sono in fase.
\item Se il primo job di tutti i task in $Tau_{i}$ termina entro il primo periodo del task $\Rightarrow$ decidere se T$_{i}$ è  schedulabile si effettua controllando se J$_{i,1}$ termina entro la scadenza tramite la funzione di tempo richiesto w$_{i,1}$ := w$_{i}$(t)
\item Altrimenti almeno un primo job di $Tau_{i}$ termina dopo il periodo del task, calcola la lunghezza $t^L$ dell'intervallo totalmente occupato di livello $\pi_{i}$ che inizia da t = 0.
\item Calcolo i tempi di risposta massimi di tutti i job di T$_{i}$ dentro l'intervallo totalmente occupato che sono $\lceil$ $\frac{t^L}{p_{i}}$ $\rceil$; il primo l'ho già calcolato.
\item Decido se questi job sono schedulabili dentro l'intervallo totalmente occupato. Uso un lemma:\\
Il tempo di risposta massimo W$_{i,j}$ del j-esimo job di T$_{i}$, in un intervallo totalmente occupato di livello $\pi_{i}$ in fase è uguale al minimo t che soddisfa l'equazione t = w$_{i,j}$(t+(j-1)$\cdot$ p$_{i}$) - (j-1)$\cdot$ p$_{i}$, con w$_{i,j}$(t) = j$\cdot$e$_{i}$ + $\sum\limits_{k=1}^{i-1}\lceil\frac{t}{p_{k}}\rceil \cdot e_{k}$.\\ Aggiungo un j che moltiplica e$_{i}$, devo verificare l'equazione nei punti multipli.\\ 
\end{itemize}
esercizio:
T$_{1}$ = ($\phi_{1}$,2,1,1), T$_{2}$ = ($\phi_{2}$,3,1.25,4), T$_{3}$ = ($\phi_{3}$,5,0.25,7)\\ Parto verificando T$_{1}$: \\w$_{1}$(t) = w$_{1,1}$(t) = e$_{1}$ = 1 = D$_{1}$. Quindi è sicuramente schedulabile . \\T$_{2}$:\\
w$_{2,1}$(2) = e$_{1}$ + e$_{2}$ = 2.25 $>$ 2, quindi non va bene. Vado avanti: \\
w$_{2,1}$(3) = 2$\cdot$e$_{1}$ + e$_{2}$ = 3.25 $>$ 3. Non va ancora bene, proseguo: \\
w$_{2,1}$(4) = 2$\cdot$e$_{1}$ + e$_{2}$ = 3.25 $\leq$ 4 $\leq$ $D_{2}$ quindi T$_{2}$ è schedulabile, ma ha completato oltre il periodo $\Rightarrow$ non posso più considerare tempi piccoli, devo considerare gli intervalli totalmente occupati, uso l'equazione iterativa:\\
$t^(1)$ = e$_{1}$ + e$_{2}$ = 2.25, sostituisco nella sommatoria,ed ottengo $t^(2)$ = 2$\cdot$e$_{1}$ + e$_{2}$ = 3.25, $t^(3)$ = 2$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ = 4.5, $t^(4)$ = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ = 5.5, $t^(5)$ = 3$\cdot$e$_{1}$ + 3$\cdot$e$_{2}$ = 5.5 $\Rightarrow$ $t^(4)$ = $t^L$, ovvero intervallo totalmente occupato di livello 2 è 5.5.\\ Ora calcolo quanti job di T$_{2}$ ci sono in (0, 5.5] = $\lceil$ $\frac{t^L}{p_{2}}$ $\rceil$ = 2.\\ Veridico il secondo job di T$_{2}$:\\
w$_{2,2}$(3) = 2$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ = 4.5 $>$ 3, no\\
w$_{2,2}$(4) = 2$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ = 4.5 $>$ 4, ancora no.\\
w$_{2,2}$(3) = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ = 5.5 $\leq$6 $\leq$ $p_{2}$+$D_{2}$=7, quindi accetto il task.\\ Ora devo capire  se posso accettare T$_{3}$, e considerare l'intervallo totalmente occupato di lvl 3:\\ 
$t^(1)$ = e$_{1}$ + e$_{2}$ +e$_{3}$ = 2.5\\
$t^(2)$ = 2$\cdot$e$_{1}$ + e$_{2}$ +e$_{3}$ = 3.5\\
$t^(3)$ = 2$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ +e$_{3}$ = 4.75\\
$t^(4)$ = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ +e$_{3}$ = 5.75\\
$t^(5)$ = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ + 2$\cdot$e$_{3}$ = 6\\
$t^(6)$ = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ + 2$\cdot$e$_{3}$ = 6 = $t^L$\\
\# job di T$_{3}$ nell'intervallo (0,6]: $\lceil$ $\frac{t^L}{p_{3}}$ $\rceil$ = 2. Considero i  singoli job:\\
w$_{3,1}$(2) = e$_{1}$ + e$_{2}$ + e$_{3}$ = 2.5 $>$ 2, no.\\
w$_{3,1}$(3) = 2$\cdot$e$_{1}$ + e$_{2}$ + e$_{3}$ = 3.5 $>$ 3, no.\\
w$_{3,1}$(4) = 2$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ + e$_{3}$ = 4.75 $>$ 4, no.\\
w$_{3,1}$(5) = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ + e$_{3}$ = 5.75 $>$ 5, no.\\
w$_{3,1}$(6) = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ + e$_{3}$ = 5.75 $\leq$ 6 $\leq$ D$_{3}$ = 7. Posso accettare il job\\\\
w$_{3,2}$(5) = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ + 2$\cdot$e$_{3}$ = 6 $>$ 5, no.\\
w$_{3,2}$(6) = 3$\cdot$e$_{1}$ + 2$\cdot$e$_{2}$ + 2$\cdot$e$_{3}$ = 6 $\leq$ 6 $\leq$ p$_{3}$ + D$_{3}$ = 12 Accetto il job, e quindi il task.\\ Tutti i task sono schedulabili a prescindere dai loro task.\\ 
\subsection{Condizioni di schedulabilità}
Il test di schedulabilità generale determina se insieme di task è schedulabile o no, considerando worst case che è task in fase.\\ Ho dei limiti:
\begin{itemize}
\item Devo conoscere tutti i periodi, le scadenze ed i tempi d'esecuzione. Per validazione è necessario, ma no per implementazione di scheduler a priorità fissa. Se voglio aggiungere un task dovrei conoscere parametri che in fase di progettazione del sw non servono.
\item Il risultato ottenuto non è valido se il task varia periodo, scadenza o tempo di esecuzione.
\item È computazionalmente costoso, poco adatto per scheduling on-line.
\end{itemize}
Cerco di trovare delle condizioni di schedulabilità, confronto il test con la condizione, che è molto più semplice da calcolare e che può essere applicata anche se alcuni parametri non sono noti (esempio: condizione di EDF).\\ Mi chiedo se $\exists$ condizione di schedulabilità per algoritmi a priorità fissa:\\ Condizione di Liu-Layland: sistema $\tau$ di n task indipendenti ed interrompibili con scadenze relative uguali ai rispettivi periodi può essere effettivamente schedulato su un processore in accordo con RM se il suo fattore di utilizzazione U$_{\tau}$ è $\leq$ a U$_{RM}$(n) = n$\cdot$($2^{\frac{1}{n}}$-1)\\ Questo è il fattore di utilizzazione di RM, se considero: $\lim_{n \to \inf}$ U$_{RM}$(n) = ln2, ovvero RM in generale garantisce di rispettare le scadenze pur di non caricare il processore per più del 69.3.\\ Ho un criterio per adottare RM negli scheduler real-time.\\ esempio:\\ T$_{1}$ = (1,0.25), T$_{2}$ = (1.25,0.1), T$_{3}$ = (1.5,0.3), T$_{4}$ = (1.75,0.07), T$_{5}$ = (2,0.1). U$_{\tau}$ = 0.62 $\leq$ 0.743 = U$_{RM}$(5) $\Rightarrow$ è schedulabile con RM.\\ IL sistema T$_{1}$ = (3,1), T$_{2}$ = (5,1.5), T$_{3}$ = (7,1.25), T$_{4}$ = (9,0.5) ha fattore di utilizzazione U$_{\tau}$ = 0.867 $>$ 0.757 = U$_{RM}$(4),  forse non schedulabile.\\ È condizione sufficiente, difatti l'esempio 2 era quello precedente che è schedulabile se applico la funzione di tempo necessario.\\ L'alternativa a questo risultato è il test iperbolico: Un sistema $\tau$ di n task indipendenti ed interrompibili con scadenze relative uguali ai rispettivi periodi può essere effettivamente schedulato su un processore RM se $\prod\limits_{k=1}^{n}(1 + \frac{e_{k}}{p_{k}})$ $\leq$ 2.\\ SI applica anche questo conoscendo solo fattore di utilizzazione dei task. \\ Correlazione con condizione di Liu-Layland: se gli n task hanno tutti lo stesso rapporto $\frac{e_{k}}{p_{k}}$ vuol dire che ciascun di questi usa una porzione uguale del processore. \\ Si può dimostrare che se questo è vero allora, assumendo u$_{k}$ = $\frac{U_{\tau}}{n}$:\\
$\prod\limits_{k=1}^{n}(1 + \frac{e_{k}}{p_{k}})$ $\leq$ 2 $\Leftrightarrow$ U$_{\tau}$ $leq$ n$\cdot$($2^{\frac{1}{n}}$-1). \\Se questo non è vero, esistono casi in cui il test iperbolico è soddisfatto, ma la condizione di Liu-Layland no; non esiste invece mai il viceversa.\\
\subsection{Test per sottoinsiemi di task armonici}
So che ,in generale RM è schedulabile se è soddisfatta condizione di Liu-Layland, ma so anche che su task armonici è ottimale. Suddivido insiemi di task in sottoinsiemi di task armonici fra loro.\\ Condizione di Kuo-Mok: se sistema $\tau$ di task periodici, indipendenti ed interrompibili con p$_{i}$ = D$_{i}$ può essere partizionato in n$_{h}$ sottoinsiemi disgiunti Z$_{1}$,....,Z${n_{h}}$, ciascuno dei quali contiene task semplicemente periodici, allora il sistema è schedulabile con RM se:\\
$\sum\limits_{k=1}^{n_{h}}U_{Z_{k}}(n_{h})$ oppure se $\prod\limits_{k=1}^{n_{h}}(1+U_{Z_{k}})$ $\leq$ 2.\\ Se un sistema ha poche applicazioni molto complesse, è possibile migliorare la schedulabilità rendendo i task di ciascuna applicazione semplicemente periodici.\\ Esempio: 9 task con periodi 4,7 ,7 , 14, 16, 28, 32, 56, 64, fattore di utilizzazione di Liu-Layland è U$_{RM}$ = 0.720\\ Considero i multipli di 2 e 7 e partizionando in due sottoinsiemi ottengo U$_{Z_{1}}$ + U$_{Z_{2}}$ $\leq$ U$_{RM}$(2) = 0.828.\\\\ Il fattore di RM è in generale U$_{RM}$(n), ma posso farlo diventare pari ad 1 per task semplicemente periodici.\\ Miglioro U$_{RM}$(n) considerando quanto i periodi dei task sono vicini ad essere armonici:\\
X$_{i}$ = log$_{2}$p$_{i}$ - $\lfloor$ log$_{2}$p$_{i}$ $\rfloor$ e $\zeta$ = max$_{1 \leq i \leq n}$X$_{i}$ - min$_{1 \leq i \leq n}$X$_{i}$\\ Considero il valore frazionario del log$_{2}$ e prendo tutti i task, di cui faccio differenza tra max e min di questi scarti decimali.\\ Teorema: nelle ipotesi della condizione di Liu-Layland, il fattore di utilizzazione di RM dipende dal numero di task n e da $\zeta$ è: 
U$_{RM}$(n, $\zeta$) =
\begin{itemize}
\item (n-1)$\cdot$($2^\frac{\zeta}{(n-1)}$-1) + $2^{(1-\zeta)}$-1  se $\zeta$ $<$ 1 - $\frac{1}{n}$
\item U$_{RM}$(n)
\end{itemize}
Quando si verifica il caso $\zeta$ = 0? Quando p$_{i}$ = K$\cdot$ $2^{x_{i}}$; non è vero il contrario\\
Variante: schedulabilità per scadenze arbitrarie. Se per qualche task la scadenza è più grande del periodo il limite è valido? Sì, però la formula è "pessimista": forse è possibile trovare valori di soglia superiori a U$_{RM}$.\\ Se invece per qualche task il periodo è più grande della scadenza non posso applicare Liu-Layland.\\ Teorema:	\\
Un sistema $\tau$ di n task indipendenti, interrompibili e con scadenze D$_{i}$ = $\delta$p$_{i}$ è schedulabile con RM se U$_{\tau}$ è $\leq$ a:
U$_{RM}$(n, $\delta$) =
\begin{itemize}
%\begin{cases}
\item $\delta$(n-1)$\cdot$($\frac{\delta+1}{\delta}^{\frac{1}{(n-1)}}$ - 1)  per $\delta$ = 2,3,.....
\item n($2\delta^{\frac{1}{n}}$-1) + 1 - $\delta$ per 0.5 $\leq$ $\delta$ $\leq$ 1
\item $\delta$ per 0 $\leq$ $\delta$ $\leq$ 0.5
%\end{cases}
\end{itemize}
\section{Schedulazione di job bloccanti e job aperiodici}
Avevo un modello semplice, devo rilassare qualcuna delle ipotesi dovute al fatto che i job siano sempre sempre interrompibili, o che costo di context switching sia 0. Nella pratica molti fattori rallentano l'esecuzione di un job, che possono portare a mancata scadenza. Devo tenerne conto, divido in due genti classi:
\begin{itemize}
\item Tempi di blocco: job non può essere eseguito nonostante il rilascio, per via di fattori esterni. Ad esempio: sul processore c'è un job non interrompibile, job rilasciato è quindi bloccato per un certo tempo. Modellati definendo b$_{i}$ = tempo massimo di blocco, che tiene conto di tutti i tempi che fanno si che il job non può eseguire, va sottratto al tempo a disposizione del job.
\item rallentamenti sistematici: ho calcolato il worst case di un job, ma a questo devo considerare il tempo che ci mette il job ad essere posto in esecuzione e ad essere tolto una volta completato, o anche il tempo che ci mette lo scheduler a decidere. Se questo tempo ha impatto pratico può avere senso modellarlo. Sommo al worst case del job.
\end{itemize}
\subsection{Auto-sospensione}
Un job rilasciato non può essere eseguito perché in attesa di eventi esterni, la cosa migliore da fare in questi casi è mettere in esecuzione un altro job. Si dice che il job si è auto-sospeso:
\begin{itemize}
\item job è un processo ed esegue operazione di accesso alla memoria di massa, ha senso sostituire il processo mentre questo attende i dati.
\item attendo dati da rete/altri job
\item attendo scadenza di un timer
\end{itemize}
Nei SO questo tipo di operazioni sono chiamate operazioni bloccanti, nell'ambito real-time ci possono essere operazioni di auto-sospensione che però non è bloccante: in questo ambito ha senso attivo, ovvero un job ne blocca un altro. Anche in questo caso ci sono conseguenze su un altro job.\\ Supponiamo che ogni job di un task T$_{i}$ si auto-sospende per un certo tempo x, in questo caso non appena rilasciato. Come schedulo: considero l'istante di rilascio come p$_{i}$-x, e la scadenza relativa come D$_{i}$-x.\\ Approccio semplificato, non funziona nel caso in cui i job si auto-sospendono solo all'inizio o per un tempo determinato, devo definire il tempo massimo di auto-sospensione b$_{i}$(ss).\\ esempio: T$_{1}$ = (4, 2.5) T$_{2}$ = (3.7, 2, 7) schedulato con RM. Se primo job di T$_{1}$ si auto-sospende subito dopo il rilascio, le cose possono andare male: il primo job del task T$_{2}$ manca la scadenza, job di T$_{1}$ si risveglia in modo che per completare occupa tutto il suo periodo, quindi quando job di T$_{2}$ comincia esecuzione di porta avanti ma non riesce a finire.\\
\includegraphics[scale=0.3]{images/SERT2210.png}\\
Ho impatto sui job di priorità inferiore: anche se job si auto-sospende on no lo fa, se c'è job di priorità superiore non è danneggiato, ma quelli di priorità inferiore si.
\subsubsection{Rallentamento dovuto all'auto-sospensione}
1° caso: il tempo di auto-sospensione di un job è maggiore della durata del job: job di T$_{i}$ con priorità inferiore è rallentato al massimo per un tempo pari alla durata del job di T$_{k}$ È il worst case: job T$_{i}$ non riesce ad arrivare mente job di T$_{k}$ è in auto-sospensione\\
\includegraphics[scale=0.3]{images/SERT2210_1.png}\\
2° caso: il tempo di auto-sospensione di un job è minore della durata del job. Un job di T$_{i}$ con priorità minore è rallentato al massimo per un tempo pari alla durata dell'auto sospensione.\\
\includegraphics[scale=0.3]{images/SERT2210_2.png}
\subsubsection{Tempo massimo di sospensione di blocco per auto-sospensione}
Dato task T$_{k}$ chiamo x$_{k}$ il tempo massimo di sospensione di ciascun job di T$_{k}$, questo è un parametro del sistema.\\ Prendo task T$_{i}$ con priorità minore, il rallentamento inflitto ad un job T$_{i}$ da un job di T$_{k}$ è minore o uguale ad x$_{k}$ e minore o uguale ad e$_{k}$:
b$_{i}$(ss) = x$_{i}$ + $\sum\limits_{k = 1}^{i-1}min(e_{k}, x_{k})$.\\ Manca qualcosa, sto assumendo che un job si auto-sospenda una volta sola, ma non c'è nessun motivo reale per cui questo sia vero: job può auto-sospendersi più volte, devo contare il numero di volte. Devo definire anche il massimo numero di volte k$_{i}$ in cui un job di T$_{i}$ si sospende.\\ Difatti:
\begin{itemize}
\item si può verificare un blocco da parte di un processo non interrompibile
\item si ha un rallentamento dovuto allo scheduler ed al costo del context switching
\end{itemize}
\subsection{Non interrompibilità dei job}
Assunzione irrealistica che i job non siano interrompibili, esistono sempre istanti in cui il job non è interrompibile:
\begin{itemize}
\item se sta operando su area di memoria critica
\item se sta interagendo con dispositivo hardware
\item job esegue syscall, e ci sono chiamate di sistema che non possono essere interrotte.Job diventa non interrompibile fino alla conclusione del SO.
\item costo del context switch è troppo elevato
\end{itemize}
Un job J$_{i}$ è bloccato per non interrompibilità quando è  pronto per essere eseguito, ma non può perché è in esecuzione un job non interrompibile.\\ Quando si verifica questo fenomeno, si parla di inversione di priorità quando la priorità del job in esecuzione è minore di quella del job pronto per l'esecuzione. esempio: T$_{1}$ = ($\epsilon$, 4, 1, 4), T$_{2}$ = ($\epsilon$, 5, 1.5, 5), T$_{3}$ = (9, 2). Qualunque sia l'algoritmo, all'istante 0 viene messo in esecuzione job di T$_{3}$, inoltre U = 0.77 ed è schedulabile per EDF e RM, ma solo se job sono non interrompibili. Suppongo che T$_{3}$ non sia interrompibile, conclude nell'istante 2, quindi tra [$\epsilon$,2] blocca due job con priorità maggiore. Nell'intervallo tra [2, 5+$\epsilon$] eseguo 3 job, 2 di T$_{1}$ ed uno di T$_{2}$, ma non c'è abbastanza tempo e quindi T$_{2}$ manca la scadenza.\\ 
\includegraphics[scale=0.3]{images/SERT2210_3.png}\\
\\Come faccio a modellare che il job è non interrompibile, devo capire la durata massima di non interrombilità di un job: sia $\\Theta_{k}$ il tempo di esecuzione massimo della più lunga sezione non interrompibile dei job di T$_{k}$. Sia b$_{i}$(np) il tempo massimo di blocco per non interrompibilità, che è tempo subito da un job a causa dei job di priorità inferiore, quando vale? b$_{i}$(np) = max\{$\Theta_{k}$: per ogni task T$_{k}$ di priorità minore a T$_{i}$ \}: suppongo che c'è job di alta priorità rilasciato, ho sul processore job di priorità inferiore T$_{k}$ appena entrato nella sezione critica non interrompibile più lunga, subisco rallentamento di $\Theta_{k}$, ma appena finisce la sezione lo scheduler da la priorità a me, non importa quanto solo lunghe le sezioni degli altri job: caso peggiore è che vengo rilasciato quando il job che ha il $\Theta_{k}$ più lungo entra in esecuzione.\\ Il tempo massimo di blocco totale dipende da entrambe i due tempi di blocco:
b$_{i}$ = b$_{i}$(ss) + (K$_{i}$+1) $\cdot$ b$_{i}$(np). Considero numero massimo di volte per cui il job J$_{i}$ si sospende, il +1 è il fatto che la prima volta deve essere rilasciato sia che si auto-sospende che non.
\subsection{Cambi di contesto}
Come modellare rallentamenti dovuti al context switch: CS= context switch time, per ora ci metto anche tempo necessario per lo scheduler per prendere decisione.\\ Allungo il worst case del job: calcolato quando non c'è nulla che interferisce col job. worst case è e'$_{i}$ = e$_{i}$ + 2 $\cdot$ (K$_{i}$ + 1) $\cdot$ CS. job deve subire almeno due cambi di contesto: quando viene messo in esecuzione e quando viene tolto dall'esecuzione.Ma ogni volta che il job si auto-sospende  c'è un altro cambio di contesto: per essere tolto e poi per essere rimesso; K$_{i}$ = n° volte che il job si auto-sospende.\\ Alle volte non è utile modellare il context switch, però in altri casi è essenziale farlo: LST si basa sullo slack rimanente, quindi ci sono molti cambi di contesto e l'overhead è significativo ed è doveroso modellarli. Con LST è anche spesso difficile capire qual'è numero massimo di context switch di job, ma ci sono algoritmi come EDF altrettanto buoni, in un sistema real-time parametro cruciale: i job devono rispettare le scadenze; utiele vederlo in teoria ma non in pratica.
\subsection{Test di schedulabilità per job bloccanti}
Come faccio ad usare i parametri definiti nel processo di validazione: o uso test di schedulabilità o uso condizioni di schedulabilità.\\ Idea è che tempo disponibile per completare per ciascun job va diminuito del tempo massimo per cui quel job può rimanere bloccato, definisco tempo di blocco come tempo max aggiuntivo. La funzione di tempo massimo richiesto diventa:\\
w$_{i}$(t) = e$_{i}$ + b$_{i}$ + $\sum\limits_{k = 1}^{i-1}\lceil \frac{t}{p_{k}} \cdot e_{k} \rceil$ per 0 $<$ t $\leq$ min(D$_{i}$, p$_{i}$). Ho meno tempo a disposizione per completare il job, sommo b$_{i}$.\\ Stesso si applica al test di schedulabilità generale:\\
w$_{i,j}$(t) = j $\cdot$ e$_{i}$ + b$_{i}$ + $\sum\limits_{k = 1}^{i-1}\lceil \frac{t}{p_{k}} \cdot e_{k}$  per (j-1)$\cdot$ p$_{i}$ $<$ t $\leq$ w$_{i,j}$(t). non devo moltiplicare b$_{i}$ per j: il 3° job di T$_{i}$ è sempre 3$ \cdot$ e$_{i}$, ma sto cercando di capire quanto tempo rimane al 3° job, perché questo viene bloccato solo per b$_{i}$. Il blocco è qualcosa che considero soltanto quando devo studiare la schedualbilità del singolo job ed è relativa solo al singolo job. Non ha senso considerarla per tutti i task insieme, si fa sempre studio task per task.
\subsection{Condizioni di schedualbilità per task bloccanti +a priorità fissa}
Sia dato sistema di n task T ed un algoritmo a priorità fissa X, con fattore di utilizzazione U$_{X}$(n). Sappiamo che il sistema è effettivamente schedulabile se U$_{T}$ $\leq$ U$_{X}$(n), a condizione che i task non blocchino mai. Come adatto la condizione per task a priorità fissa ma che bocchino? Non posso più usare solo le condizioni di schedualbilità, perché ciascun job può bloccare con misura differente, quindi devo farlo per un task alla volta. Nel caso peggiore, ogni job di T$_{i}$ impiega un tempo e$_{i}$ + b$_{i}$ per completare l'esecuzione. Posso modellare questo tempo come tempo di esecuzione in più che il job deve subire: dato un task T$_{i}$, calcolo utilizzazione totale fino alla priorità i, dato task calcolo utilizzazione totale fino alal priorità i:\\ $\sum\limits_{k = 1}^{i}\frac{e_{k}}{p_{k}} + \frac{b_{i}}{p_{i}}$ $\leq$ U$_{X}$(i). Task di priorità inferiore non possono incidere sulla priorità del task, o meglio lo faranno solo se sono non bloccanti ma lo sto già considerando. Guardo solo ai task con priorità maggiore, considero come n° task solo fino ad i, considero solo U$_{X}$(i), man mano arriverò ad U$_{X}$(n).
Applico anche ad EDF, considero task per task, parlo in generale di densità ed uso approccio simile al precedente: task per task questo è schedualbile se:\\ $\sum\limits_{k = 1}^{n}\frac{e_{k}}{min(D_{k}, p_{k})}$ + $ \frac{b_{i}}{min(D_{i}, p_{i})}$ = $\Delta_{\tau}$ + $\frac{b_{i}}{min(D_{i}, p_{i})}$ $\leq$ 1.\\ Non sto parlando di task a priorità fissa, ogni job del sistema può avere priorità che precede il job in questione: di fatto, non posso applicare sommatoria solo a task a priorità superiore ma devo applicare a tutti i task del sistema, quindi arrivare alla densità del sistema. Alla densità contribuisce anche il task in questione che è $ \frac{e_{i}}{min(D_{i}, p_{i})}$, a cui aggiungo anche $ \frac{b_{i}}{min(D_{i}, p_{i})}$ poiché è come se il tempo di esecuzione del job del task è aumentato di b$_{i}$.\\ Problema è definire i tempi massimi di blocco se i task non hanno priorità fissata, la priorità è del job. \\ Teorema (Baker, 1991): in una schedualzione EDF un job con scadenza relativa D può bloccare un altro job con scadenza relativa D' solo se D $>$ D'.\\ Dim: se il job con scadenza relativa D blocca quello con D', vuol dire che la sua priorità è inferiore: bloccare ha il senso che un job a priorità inferiore sta togliendo tempo ad uno a priorità superiore, quindi d $>$ d' (scadenze assolute), per poter bloccare il processore deve averlo messo in esecuzione prima e quindi r $<$ r' $\Rightarrow$ D = d-r $>$ d'-r' = D'.
Ho una soluzione: posso ordinare i task per scadenze relative crescenti, ed applico la formula di b$_{i}$ per i task con priorità fissa.\\ Caso dell'auto-sospensione è difficile, quindi come realizzare il teorema di Baker? Thm non è più valido: se per esempio job J' ha priorità più alta di un job J. Se J' comincia ad eseguire e si auto-sospende: prima di tornare in esecuzione comincia job di priorità più bassa. L'ipotesi che r sia $<$ r' non è più vera, può essere dopo r' semplicemente perché il job si è autosospeso: dovrei applicare al tempo r'+tempo dopo la sospensione.\\ Posso applicare il ragionamento a r'+x'+e': di quanto tempo r può precedere r', sicuramente di x'+e'.Può non precedere r', ma r'+x'+e' è la massima distanza che posso avere fra r ed r'. Formulo teorema di Baker con auto-sospensione: in una schedulazione EDF, un job con scadenza relativa D può bloccare un altro job con scadenza relativa D' e tempo massimo di esecuzione x' solo se D $>$ D'-x'-e'.\\ Dato che entrambi i job possono auto-sospendersi, è possibile che i due task possano bloccarsi a vicenda non ho più ordinamento totale.
\subsection{Schedulazione basata su tick}
Fin'ora ho visto scheduler event-driven: viene eseguito quando si verifica un evento rilevante. In pratica, è più semplice realizzare uno scheduler time-driven, ovvero che si attiva ad interruzioni periodiche: svantaggio è che tutti i tempi nel sistema avranno granularità pari alla dimensione del mio tick.\\ Il riconoscimento di un evento come il rilascio di un job può essere differito fino al tick successivo, è come se ci fosse inversione di priorità. Definisco job pendenti, ovvero che sono stati rilasciati ma che lo scheduler non ha ancora preso in considerazione perché non è scattato il tick, e quelli eseguibili, ovvero quelli piazzati dallo scheduler, ho due code per le rispettivi due classi. Scheduler sposta job da coda dei job pendenti a coda dei job eseguibili.Quando jop termina, so già qual'è il prossimo da eseguire: sarà quello successivo nella coda dei job eseguibili. Se arriva job, questo viene messo nella coda dei job pendenti.
\subsubsection{Test schedulabilità per priorità fissa con tick}
Come posso applicare il test di schedulabilità ad uno scheduler a priorità fissa basato su tick?\\ Considero scheduler che si attiva con periodicità p$_{0}$, esegue in tempo e$_{0}$ il controllo della coda di job pendenti e con CS$_{0}$ trasforma un job da pendente a eseguibile.\\  Per controllare la schedulabilità di T$_{i}$
\begin{itemize}
\item Devo aggiungere task per controllare schedulabilità di un task T$_{0}$ = (p$_{0}$, e$_{0}$) a priorità massima.
\item Devo modellare il fatto che qundo arriva job, questo va prima o poi trasformato da pendente ad eseguibile. 
\begin{itemize}
\item per tutti i task a priorità inferiore rispetto ai job di T$_{i}$, per cui devo tenere conto del fatto che lo scheduler interverrà e trasformerà il job pendente in un job nella coda eseguibile. Oltre ai job di priorità inferiore, che vanno da i+1 a n, aggiungo un numero corrispondete di task T$_{0,k}$ = (p$_{k}$, CS$_{0}$) per ogni k = i+1,..,n, con priorità maggiore di T$_{1}$, ma che hanno periodicità CS$_{0}$, ovvero il tempo che ci mette il processore a trasformare i job in eseguibile da pendenti.
\item job a priorità superiore, aggiungo a tutti i task di priorità superiore o uguale ad (K$_{k}$ + 1) $\cdot$ CS$_{0}$, considero K$_{k}$ perché ogni volta che mi risveglio devo essere spostato da pendente ad eseguibile. Aggiungo questi valori ad e$_{k}$ per ogni k = 1,2...,i.
\end{itemize}
Perché non considero le auto-sospensione per i task a priorità inferiore? Perché task inferiore non viene mai eseguito al posto mio, pago solo il primo rilascio, perché fin quando io sono eseguibile, quelli con meno priorità di me non hanno possibilità di essere eseguiti prima di me.
\item Devo anche considerare il tempo di blocco per non-interrompibilità, anche se tutti i miei job sono sempre non interrompibili. b$_{i}$(np) = ($\lceil max_{i+1 \leq k \leq n}\frac{\Theta_{k}}{p_{0}}\rceil$ + 1) $\cdot$ p$_{0}$. max $\Theta_{k}$ moltiplicato il p$_{0}$ diventa il max di tutti i $\Theta_{k}$ di priorità inferiore, in più c'è un p$_{0}$. esempio:\\
\includegraphics[scale=0.3]{images/SERT2210_4.png}\\
ho lo shceduler che viene invocato con periodo p$_{0}$. Ad un certo istante viene rilasciato il job del task T$_{i}$, mi metto nel worst case, ovvero il job T$_{i}$ arriva un infinitesimo dopo che lo scheduler ha finito di controllare la coda dei job pendenti, quindi fino al prossimo p$_{0}$ non potrò eseguire il job. In questo periodo, prima che possa intervenire lo shceduler, si continua ad eseguire un job di priorità inferiore di T$_{k}$ e questo job entra nella regione interrompibile all'interno del periodo p$_{0}$ in cui è arrivato T$_{i}$, task T$_{k}$ continua l'esecuzione per un numero di periodi pari a $\frac{\Theta_{k}}{p_{0}}$. Solo quando scheduler interviene si rende conto che job di T$_{k}$ è diventato interrompibile e può entrare T$_{1}$, e c'è la parte intera superiore perché se il n° di periodi non è intero,anche la frazione non completata porta via tempo e devo aspettare comunque il periodo successivo; il +1 è il rilascio, almeno un periodo lo devo aspettare anche se non ho sezione critica, il job è arrivato prima.
\end{itemize}
esempio: T$_{1}$ = (0.1, 4, 1, 4.5), T$_{2}$ = (0.1, 5, 1.8, 7.5), T$_{3}$ = (0, 20, 5, 19.5) non interrompibile in [r$_{3}$, r$_{3}$+1.1]. Scheduler ha p$_{0}$ = 1, e$_{0}$ = 0.05, CS$_{0}$ = 0.06.\\ Faccio analisi dei singoli task:\\
Verifico T$_{1}$: sistema equivalente è T$_{0}$ = 1,0.05), T$_{0,2}$ = (5,0.06), T$_{0,3}$ = (20,0.06), T$_{1}$ = (4,1.06), b$_{1}$ = 3.\\ w$_{1}$(t)
 = 1.06 + $\lceil \frac{t}{1}\rceil$0.05 + $\lceil \frac{t}{5}\rceil$0.06 + $\lceil \frac{t}{20}\rceil$0.06.\\
w$_{1}$(4.06) = 4.43 $\leq$ w$_{1}$(4.43) $\leq$ 4.5, quindi ok.\\
Procedo per T$_{2}$ e T$_{3}$ sempre considerando il sistema equivalente.\\ w$_{2}$(4.86) = 7.29 $\leq$ w$_{2}$(7.29) $\leq$ 7.5, quindi ok.\\
w$_{3}$(6.06) = 12.25,  w$_{3}$(12.25) = 16.53, w$_{3}$(16.53) = 19.65, w$_{1}$(19.65) = 19.8 $>$ 19.5, quindi no.\\ Devo concludere che il sistema non è validato, e va ri-progettato.
\subsubsection{Condizione di schedulabilità su tick}
Per ciascun T$_{i}$ da controllare faccio quanto segue:
\begin{itemize}
\item Uso il thm Baker ed ordino per scadenze relative crescenti
\item aggiungo un task T$_{0}$ =(p$_{0}$,e$_{0}$) di massima priorità
\item Aggiungo (K$_{k}$+1)$\cdot$CS$_{0}$ al tempo i esecuzione e$_{k}$, devo farlo per tutti i task: i blocchi hanno una certa relazione ma non ho priorità fissate, quindi ogni job può portare via tempo ad un altro job nel sistema
\item Tempo di blocco è b$_{i}$(np) = ($\lceil max_{i+1 \leq k \leq n}\frac{\Theta_{k}}{p_{0}}\rceil$ + 1) $\cdot$ p$_{0}$.
\end{itemize}
Nell'esempio di prima, ottengo densità totale $\Delta$ $\simeq$ 0.95., verifico T$_{1}$: prendo $\Delta$ e sommo $\frac{3}{4}$, ovvero tempo di blocco diviso periodo di T$_{1}$. Ottengo 1.69 $>$, quindi non schedualbile. Mi posso fermare: basta trovare un task non schedulabile.
\subsection{Schedulazione priority-driven di job aperiodici}
Mi pongo il problema di dover gestire job che arrivano ad istanti di tempo non predicibili:
\begin{itemize}
\item Job aperiodici sfot-rt: non faccio nulla, voglio però che completino nel miro tempo possibile.
\item Job aperiodici hard-rt: tempi di arrivo sconosciuti, durata sconosciuta e scadenze hard.
\end{itemize}
Se non ho nessuna ipotesi su tempi di arrivo ed esecuzioni non posso prendere impegni: potrà sempre arrivare qualcosa che non mi permette di rispettare le scadenze.\\ Richiedono algoritmi differenti, però devono essere corretti ed ottimali: le scadenze vanno rispettate, i job aperiodici hard-rt va rifiutato se non è possibile garantirne le scadenze.Inoltre: tempi di risposta dei job soft-rt non hanno scadenze ma vanno minimizzato i tempi di risposta.
\subsubsection{Schedulazione di job aperiodici soft RT in background}
Metto in coda apposta e quando job è in background eseguo il job aperiodico in cima alla coda. Algoritmo è corretto, i task periodici non sono influenzati, ma non è ottimale: ritardo job aperiodici senza motivo.esempio:\\
T$_{1}$ = (3,1), T$_{2}$ = (10,4) job aperiodico A con rilascio 0.1 e durata 0.8.\\
\includegraphics[scale=0.3]{images/SERT2210_5.png}\\
\subsubsection{Schedulazione di job aperiodici soft RT interrupt-driven}
Esegui job aperiodici nel mo,mento in cui li rilasci, algortimo non è corretto ma è ottimo: job aperiodici finiscono nei tempi minimi, ma task periodici possono mancare le scadenze.\\
\includegraphics[scale=0.3]{images/SERT2210_6.png}\\
\subsubsection{Schedualzione di job aperiodici soft RT con slack stealing}
Algoritmo esegue i job aperiodici in anticipo rispetto a quelli periodici finché c'è uno slack globale positivo.\\ È corretto perché i job periodici non perdono le scadenze. È ottimale, solo per job aperiodico in cima alla coda. Svantaggio è che tenere uno slack globale in uno scheduler priority divern è difficile.
Job aperiodico riprende quando lo slack torna positivo.\\
\includegraphics[scale=0.3]{images/SERT2210_7.png}\\
\subsubsection{Schedulazione di job aperiodici soft RT con polling}
Algoritmo basato su polling, ovvero nel sys di task periodici introduco server di polling o poller, a cui do un certo periodo p$_{s}$ e tempo di esecuzione e$_{s}$ e gli do priorità massima,così da ridurre i tempi di risposta dei job aperiodici. Server controlla coda job aperiodici, se vuota si auto-sospende fino a prossimo tick, altrimenti esegue per al più
e$_{s}$ unità di tempo, per poi auto-sospendersi.\\ 
\includegraphics[scale=0.3]{images/SERT2210_8.png}\\
È corretto se dimensiono il poller in modo tale che il suo fattore di utilizzazione non ecceda quello dell'algoritmo di schedulazione, è come aggiungere un task periodico che ha worst case pari ad e$_{s}$. \\ Non è ottimale, job aperiodico può arrivare subito dopo esecuzione del poller. Nell'esempio forse potevo anticipare l'esecuzione del job A senza far mancare le scadenze. Posso migliorare le capacità del server? Sì.
\subsubsection{Server periodici}
I server periodici sono una classe di task periodici aventi:
\begin{itemize}
\item periodo p$_{s}$
\item budget e$_{s}$
\item dimensione u$_{s}$ = $\frac{e_{s}}{p_{s}}$
\end{itemize}
Hanno due regole:
\begin{itemize}
\item regola di consumo che dice come il budget viene consumato
\item regola di rifornimento: come il budget viene ripristinato
\end{itemize}
Server di dice impegnato quando ha del lavoro da svolgere, ovvero la coda dei job aperiodici non è vuota, idle nel caso contrario. È eleggibile, pronto o schedulabile se è impegnato ed il suo budget è $>$ 0. Il poller può essere descritto come server periodico, è impegnato se la coda dei job non è vuota, la regola di consumo è che sottrae il tempo impiegato ad eseguire il job aperiodico dal budget; le coda dei job aperiodici è vuota il budget viene azzerato.\\ Budget rifornito del suo valore massimo e$_{s}$ all'inizio di ogni periodo p$_{s}$.
\subsection{Algoritmi a conservazione di banda}
Problema del server di polling è che se si svuota la coda, il server ha budget azzerato. Se subito dopo arriva un job che potrebbe essere subito  dal server non può farlo: questo comporta ritardo di esecuzione. VOlgio un algoritmo in cui un budget non venga azzerato se la coda è vuota, in modo da migliorare tempi di risposta se arrivano job aperiodici. Esistono molti algoritmi a conservazione di banda.3 di cui parleremo:
\begin{itemize}
\item Server procrastinabile
\item Server sporadico
\item Server a utilizzazione costante
\end{itemize}
Sono già molto sofisticati, usarne di più sofisticati comporterebbe overhead computazionale elevato. Questi algoritmi usati anche altrove, es gestione code di pacchetti.
\subsection{Server procrastinabile}
Server più semplice possibile. Devo definire le regole di consumo e riferimento, premesso che ho consumo p$_{s}$ e budget p$_{s}$. Regola di consumo: budget è decrementato di 1 per ogni unità di tempo in cui il server è in esecuzione (è proporzionale, quindi se è meno di 1 unità perdo meno di 1 unità). Non viene azzerato il budget se la coda dei job aperiodici è vuota.\\ Regola di rifornimento: ad ogni istante multiplo di p$_{s}$, il budget è impostato ad e$_{s}$. Nota bene: il budget non si accumula, quello che non spendo viene perso.
\includegraphics[scale=0.3]{images/SERT2310.png}
\\ stesso esempio di prima, all'istante 0 coda è vuota e quindi scheduler seleziona qualcun altro, quando a 0.1 arriva job aperiodico, questo interrompe job di T$_{1}$ ed esegue per 0.5 che è il budget massimo. Questo tipo di server minimizza tempo di risposta del job aperiodico. esempio: schedulazione a priorità fissa\\
\includegraphics[scale=0.3]{images/SERT2310_1.png}.\\ All'inizio server non ha nulla da fare, va in esecuzione job di T$_{2}$, le cose cambiano quando all'istante 2.8 arriva il job aperiodico di durata 1.7, server ha priorità superiore, budget è positivo quindi è eleggibile e quindi esegue fino a 3. All'istante 3 cade il periodo del server, quindi budget è rifornito ad 1 ed esegue fino anche non finisce.Va eseguito altro, rimetto dentro il job di T$_{1}$, dopo di che non succede nulla: processore è idle anche se avrebbe qualcosa da fare, job aperiodico non è finito, ma algoritmo continua a non schedulare job. All'istante 6 termino job aperiodico e tutto procede. È vero che l'algoritmo cerca di anticipare esecuzione dei job aperiodici, ma non è perfetto. Non è ad esempio come un slack stealing, ho dei limiti: intervallo in cui processore è idle.\\ Posso fare la stessa schedulazione con EDF, in questo caso server non ha la priorità più grande: la priorità è data dalla scadenza assoluta che è data implicitamente dai periodi del server.Schedulazione simile a quella di prima, ci anche sono degli istanti in cui il processore è idle.\\ È possibile applicare condizioni di schedulabilità a sistemi a priorità fissa con server procrastinabile? La difficoltà è che il caso peggiore non è più vero, perché il server procrastinabile non ha un comportamento simile agli altri task periodici. Se il server è eleggibile e nessun task di priorità maggiore è in esecuzione viene subito eseguito, ma qui non appena arriva job aperiodico task diviene eleggibile, ma non so in che istante arriva il job: server con budget $>$ 0 può diventare eleggibile in qualunque momento. esempio: T$_{DS}$=(3,1.2), T$_{1}$=(3.5,1.5), r$_{1,c}$=10, r$_{A}$=10, e$_{A}$ $>$ 3, budget(10)=1.2, fase=2.2\\ All'istante 10 viene rilasciato job di T$_{1}$, ma all'istante 10 sto anche eseguendo job molto lungo aperiodico, questo job viene eseguito fino allo scadere del budget. Caso peggiore vuole che a 11.2 c'è scadenza del periodo del server, quindi budget è nuovamente incrementato, quindi esegue per un altro tempo e si azzera a 12.4, ma a 12.4 non c'è più abbastanza tempo per eseguire job di T$_{1}$. Assunzione non più vera: job arriva in un qualsiasi momento, configurazione è tale per cui job continua ad eseguire per un tempo più lungo di quello che doveva ed intacca job regolare.
\subsubsection{Istanti critici per server procrastinabili}
Sistema di task periodici indipendenti e interrompibili, e priorità fissa con D$_{i}$ $\leq$ p$_{i}$ ed un server procrastinabile (p$_{s}$, e$_{s}$) con priorità massima, un istante critico di un task T$_{i}$ si verifica all'istante t$_{0}$ se 
\begin{itemize}
\item a t$_{0}$ è rilasciato un job di tutti i task T$_{1}$,...,T$_{i}$
\item a t$_{0}$ il budget del server è e$_{s}$
\item a t$_{0}$ è rilasciato almeno un job aperiodico che impegna il server da t$_{0}$ in avanti
\item l'inizio del successivo periodo del server è t$_{0}$ + e$_{s}$
\end{itemize}
Nelle ipotesi del lemma, quanto tempo di processore occupa al massimo il server nell'intervallo (t$_{0}$, t]. Devo aggiungere questo tempo alla funzione di tempo necessario di T$_{i}$. Tempo totale: devo considerare anche il periodo troncato prima di t perché il server ha priorità massima, ho sicuro un e$_{s}$, poi ho e$_{s}$ per il numero di intervalli:
e$_{s}$ + $\lceil \frac{t-t_{0}-e_{s}}{p_s}\rceil \cdot e_s$.\\ Ora posso modificare la funzione di tempo necessario per tenere conto del server procrastinabile:\\ 
w$_{i}$(t) = e$_{i}$ + b$_{i}$ + e$_{s}$ + $\lceil \frac{t-t_{0}-e_{s}}{p_s}\rceil \cdot e_s$ + $\sum\limits_{k = 1}^{i-1}\lceil \frac{t}{p_{k}}\rceil \cdot e_k$ per 0 $<$ t $\leq$ p$_{i}$.\\ Il test controlla se w$_{i}$(t) $\leq$ t per i valori di t $\leq$ D$_{i}$ tali che t = h $\cdot$ p$_{k}$ oppure t = e$_{s}$ +  h $\cdot$ p$_{s}$, oppure t = D$_{i}$(h=0,1,...)\\ Stesso avviene per il test di schedulabilità generale:\\ j$\cdot$ e$_{i}$ + b$_{i}$ + e$_{s}$ + $\lceil \frac{t-t_{0}-e_{s}}{p_s}\rceil \cdot e_s$ + $\sum\limits_{k = 1}^{i-1}\lceil \frac{t}{p_{k}}\rceil \cdot e_k$ per 0 $<$ t $\leq$ p$_{i}$ per (j-1)$\cdot$ p$_{i}$ $<$ t $<$ w$_{i,j}$(t).\\ L'esempio nel caso precedente mostra che il task T$_{1}$ non è schedulabile.\\ Posso anche realizzare un sistema in cui server non ha priorità massima, condizione mi da risultato pessimista ma la condizione è solo sufficiente (può dare falsi negativi).
\subsubsection{Condizione di schedulabilità RM con server procrastinabile}
Teorema: un server procrastinabile con periodo p$_{s}$ e budget e$_{s}$ ed n task periodici indipendenti ed interrompibili , con p$_{i}$ = D$_{i}$ e tali che:\\ p$_{s}$ $<$ p$_{1}$ $<$... $<$ p$_{n}$ $<$ 2p$_{s}$ e p$_{n}$ $>$ p$_{s}$ + e$_{s}$ sono schedulabili con RM se l'utilizzazione totale è:\\
U$_{RM/DS}$(n) = $\frac{e_s}{p_s}$ + [$(\frac{e_s + 2p_s}{p_s +2e_s})^{\frac{1}{n}}$ -1]. Molto simile alla formula di Liu-Layland, facile verificare che se e$_{s}$ = 0, ottengo esattamente U$_{RM}$(n), ma ora $\lim_{x \to inf}$ U$_{RM/DS}$(n) = $\frac{e_s}{p_s}$ + ln($\frac{e_s + 2p_s}{p_s +2e_s}$).\\ Mi dice quanto è il carico massimo che posso dare al sistema quando c'è server procrastinabile in modo da garantire le scadenze, valgono però le ipotesi molto forti.\\ Se le condizioni non si verificano, bisogna effettuare analisi task per task:
\begin{itemize}
\item Server non ha alcuna influenza sui task con periodo minore di p$_{s}$
\item Server è schedulabile se lo è il corrispondente task periodico
\item Per i task di priorità inferiore devo prevedere che il server può bloccare per un tempo e$_{s}$ in più, aggiungo alla formula il tempo di blocco aggiuntivo:\\ $\sum\limits_{k = 1}^{i-1} \frac{e_k}{p_k}$ + $\frac{e_s}{p_s}$ + $\frac{e_s + b_i}{p_i}$ $\leq$ U$_{RM}$(i+1).\\ Aggiungo anche ritardo e$_{s}$ in più che è il primo intervallo, il ritardo dovuto al fatto che nell'istante critico per T$_{1}$ vengo rallento di un istante in più rispetto al tempo normale. Confronto al limite di Liu-Lyland per i+1 task perché includo anche il server.
\end{itemize}
\subsubsection{Condizione di schedulabilità di EDF con server procrastinabile}
Un task periodico T$_{i}$ in un sistema di n task indipendenti ed interrompibili è schedulabile con EDF insieme ad un server procrastinabile (p$_{s}$, e$_{s}$) se:\\ $\sum\limits_{k = 1}^{n} \frac{e_k}{min(D_k, p_k)}$ + $\frac{e_s}{p_s}$ $\cdot$ (1 + $\frac{p_s - e_s}{D_i}$) $\leq$ 1.\\ Dim: per D$_{k}$ $\leq$ p$_{k}$. Suppongo che un job di T$_{i}$ rilasciato a r$_{i}$ manca la scadenza a t; t' $<$ t è l'ultimo istante in cui il processore è idle o esegue un job a priorità inferiore. Ma allora r$_{i}$ $\geq$ t', questo significa che l'istante t in cui manco la scadenza assoluta meno t' è maggiore o uguale alla scadenza relativa. Ma quindi, invertendo: $\frac{1}{t-t'}$ $\leq$ $\frac{1}{D_i}$. Quando tempo viene rubato dal server procrastinabile tra t' e t: $e_{s}$ + $\lfloor \frac{t - t'- e_s}{p_s}\rfloor \cdot e_s$, la parte intera è inferiore perché se t cade nel mezzo vuol dire che il server procrastinabile avrà una scadenza che sarà dopo, la frazione va scartata in quanto non ruberà tempo.\\
\includegraphics[scale=0.3]{images/SERT2310_3}\\
Quindi t-t' $<$ $\sum\limits_{k=1}^{n} \frac{e_k}{p_k} \cdot (t-t')$ + $\frac{e_s}{p_s}$ $\cdot$ (t-t'-p$_s$-e$_{s}$). L'intervallo non è sufficiente a fare tutto il lavoro: il lavoro è eseguire tutti i job periodici, in più il tempo del server procrastinabile nell'intervallo t-t' ed in più +p$_{s}$ - e$_{s}$, togliendo la parte intera. Ma sto dicendo che la sommatoria + il resto è $>$ 1, ovvero se la condizione è $\leq$ 1 il task periodico rispetterà la scadenza.
\subsection{Server sporadici}
Un server procrastinabile può ritardare i task di priorità minore più di un task periodico con identici parametri. Vorrei avere un server con impatto su schedulabilità del sistema uguale a quello di un qualsiasi task periodico: server sporadico, shcedulabilità del sistema si studia semplicemente, ne esistono vari tipi: differenza sta nelle regole di consumo/rifornimento.
\subsubsection{Server sporadici in sistemi a priorità fissa}
Sistema di task periodici T a priorità fissa, ho un server sporadico T$_{s}$=(p$_{s}$, e$_{s}$), con priorità $\pi_{s}$. Definisco l'insieme T$_{H}$, che è l'insieme dei task con priorità maggiore di $\pi_{s}$.\\ Definisco l'intervallo totalmente occupato di un insieme di task:
\begin{itemize}
\item prima dell'intervallo tutti i job sono stati completati
\item all'inizio dell'intervallo viene rilasciato almeno un job
\item la fine dell'intervallo è il primo istante in cui tutti i job rilasciati entro l'intervallo sono completati
\end{itemize}
Definisco alcuni parametri e variabili:
\begin{itemize}
\item t$_{r}$: l'ultimo istante in cui è stato aumentato il budget, ovvero l'ultimo istante in cui è stata applicata la regola di rifornimento del server.
\item t$_{f}$, che è il primo istante dopo t$_{r}$ in cui il server è in esecuzione.
\item t$_{e}$ è invece una variabile che serve per indicare quando ci sarò il prossimo rifornimento, tipicamente sarà t$_{e}$ + $\pi_{s}$.
\item BEGIN: variabile che per ogni t, considera l'ultima sequenza di intervalli totalmente occupati contigui dei task T$_{H}$ iniziata prima di t. BEGIN è esattamente l'inizio del primo intervallo totalmente questa sequenza.
\item END è la fine, ma solo se la fine è precedente a t, altrimenti è $\infty$.
\end{itemize}
\subsubsection{Server sporadico semplice}
Regola di consumo: in ogni istante maggiore di t$_{r}$, il budget è decrementato di una unità per ogni unità di tempo se una delle seguenti condizioni è vera:
\begin{enumerate}
\item Il server è in esecuzione
\item Il server è stato in esecuzione dopo t$_{r}$ ed inoltre END $<$ t.
\end{enumerate}
Se le condizioni sono false, il budget si conserva. Il server consuma budget più in fretta del server procrastinabile, stiamo cercando di ridurre l'impatto che ha sui task di priorità inferiore.\\  Regole di rifornimento:
\begin{enumerate}
\item Ogni volta che faccio rifornimento, il budget è settato ad e$_{s}$, t$_{r}$ viene associato all'istante corrente
\item All'istante t$_{f}$:
\begin{itemize}
\item se END = t$_{f}$, allora associa a t$_{e}$ il max(t$_{r}$, BEGIN)
\item se END $<$ t$_{f}$, associa a t$_{e}$ il valore di t$_{f}$.
\end{itemize}
\item Il prossimo rifornimento sarà a t$_{e}$+p$_{s}$, ma con due eccezioni:
\begin{itemize}
\item se t$_{e}$+p$_{s}$ $<$ t$_{f}$, il budget sarà rifornito non appena esaurito
\item il budget sarà rifornito ad un certo momento t$_{b}$ $<$ t$_{e}$+p$_{s}$ se esiste un intervallo [t$_{i}$, t$_{b}$) in cui nessun task di T è eseguibile, ed un task di T comincia l'esecuzione a t$_{b}$
\end{itemize}
\end{enumerate}
Significato della regola di consumo 1: nessun job del server esegue per un tempo maggiore di e$_{s}$ in un periodo p$_{s}$\\ Significato di C2: il server conserva budget se un task di T$_{H}$ è eseguile oppure il server non ha mai eseguito t$_{r}$; altrimenti il budget è consumato.\\ Significato di R2: se nell'intervallo (t$_{r}$, t$_{f}$) sono stati sempre in esecuzione task di T$_{H}$, il prossimo rifornimento sarà a t$_{r}$+p$_{s}$. Ma se questo non è vero il prossimo rifornimento sarà a t$_{e}$+p$_{s}$ dove t$_{e}$ è l'ultimo istante di (t$_{r}$, t$_{f}$] in cui non esegue un task di T$_{H}$.\\ Significato di R3a: il job del server ha atteso per più di p$_{s}$ unità di tempo prima di iniziare l'esecuzione, quindi il job continua nel prossimo periodo (serve il test di schedulabilità generale).\\ R3b: il budget è rifornito nell'ostante iniziale di ogni intervallo totalmente occupato di T. \\ esempio di schedulazione RM con server sporadico semplice:\\
\includegraphics[scale=0.3]{images/SERT2310_4.png}\\
Da 3.5 comincio T$_{f}$ e consumo il budget, ma ora devo anche capire t$_{e}$, che qui è 3. Questo mi dice anche quando sarà il prossimo rifornimento, che sarà ad 8 (3+5). All'istante 5.5 termina il job aperiodico, e qui lo scheduler da il controllo al job di T$_{3}$, ma il budget continua ad essere consumato fino a diventare 0: non sono più nelle condizioni in cui il budget si preserva, e qui sta eseguendo un job con priorità minore del server. All'istante 7 arriva il 2° job aperiodico ma non posso eseguirlo perché il budget è 0, quindi devo aspettare 8. A 9.5 termina l'intervallo totalmente occupato, quindi posso eseguire job aperiodici.
\subsubsection{Server sporadico background}
Variante del server sporadico (ne esistono di verse via via sempre più costose da implementare). Ogni volta che nessun job periodico è eseguibile, il server esegue un job aperiodico.\\ Regola di consumo è identica a quella del server sporadico semplice, tranne che se nessun task periodico è eseguibile il budget è uguale a e$_{s}$. \\ regola di consumo è uguale tranne che per R3b: il budget è ripristinato all'inizio di ogni intervallo in cui nessun task periodico è eseguibile; t$_{r}$ (ed eventualmente t$_{f}$) è la fine dell'intervallo.\\ Conviene sempre implementare questo server, perché questo tende ad abbassare il tempi di risposta dei job aperiodici, l'unico caso in cui non conviene usarlo è quando si utilizzano più server sporadici per differenti tipi di job aperiodici.\\ esempio precedente:\\
\includegraphics[scale=0.3]{images/SERT2310_5.png}\\ 
Da un certo punto in poi budget rimane sempre al valore massimo, per un motivo o per un altro.
\subsection{Constant Bandwidth server}
Server inventato da L. Abeni e G. Buttazzo (1998). Server abbastanza recente, importante per diversi motivi:
\begin{itemize}
\item Server abbastanza facile da integrare in uno scheduler a priorità fissa a livello di job
\item Schedulazione di job aperiodici con i vantaggi di EDF rispetto a RM/DM
\item server è work conserving: non lascio mai processore idle se c'è almeno un job da eseguire.
\item occupazione del processore non supera mai una frazione di tempo predefinita: permette di isolare il comportamento del server dal comportamento dei task aperiodici
\end{itemize}
Caratteristiche:
\begin{itemize}
\item periodo p$_{s}$
\item budget massimo e$_{s}$
\item budget corrente c$_{s}$
\item scadenza assoluta d$_{s}$: questo perché il server va schedulato in un algoritmo di tipo EDF, devo confrontare la priorità con quella degli altri task che è basato su scadenza assoluta.
\end{itemize}
Il rapporto u$_{s}$ = $\frac{e_s}{p_s}$ è la bandwidth del server.\\ Il server CBS viene schedulato con EDF insieme agli altri task periodici considerando la scadenza assoluta corrente d$_{s}$.\\ Un sistema di task periodici ed un server CBS sono schedulabili con EDF se U$_{T}$ + u$_{s}$ $\leq$ 1.\\ Funzionamento del server:\\
\begin{itemize}
\item Regola di aggiornamento della scadenza:
\begin{itemize}
\item inizialmente d$_{s}$ = 0
\item non appena budget corrente si azzera, la scadenza diviene pari a d$_{s}$+p$_{s}$, la priorità viene diminuita in modo da dare spazio agli altri task del sistema
\item Se ad un certi istante t viene rilasciato job aperiodico ed il server non è impegnato (la coda dei job aperiodici è vuota) , vado a verificare se c$_{s}$ $\geq$ (d$_{s}$-t) $\cdot$ u$_{s}$, perché se questo avviene rischio di prendere più tempo del processore del dovuto e quindi setto d$_{s}$ a t+p$_{s}$.
\end{itemize}
\item Regola di rifornimento e di consumo:
\begin{itemize}
\item all'inizio imposto il valore di c$_{s}$ ad e$_{s}$
\item c$_{s}$ viene decrementato proporzionalmente all'esecuzione dei job periodici del server.
\item se c$_{s}$ di azzera, c$_{s}$ viene rifornito ad e$_{s}$ immediatamente
\end{itemize}
Non esiste mai un intervallo di tempo $>$ 0 in cui il server ha un budget nullo.
\end{itemize}
esempio EDF con server CBS:\\
\includegraphics[scale=0.3]{images/SERT2310_6.png}
\subsection{Schedulabilità di job aperiodici hard real-time}
Concetto di densità del job aperiodico con istante di rilascio r e tempo massimo di esecuzione e e scadenza la sua densità è: $\frac{e}{d-r}$.\\ Vale questo teorema: Un sistema di job aperiodici, indipendenti e interrompibili è schedulabile con EDF se la densità totale di tutti i job attivi (nell'intervallo tra rilascio e scadenza) è in ogni istante $\leq$ 1.\\ In ogni istante di tempo la densità totale di tutti i job rilasciati e non ancora conclusi deve essere $\leq$ 1; è una condizione sufficiente, teorema permette di realizzare anche un test di accettazione. Dim: un job manca la scadenza a t, t' è l'ultimo momento in cui il processore non ha eseguito un job con scadenza $\leq$ t $\Rightarrow$ $\sum\limits_{i} e_i$ $>$ t-t'. Partiziono l'intervallo fra (t',t] in (t$_{1}$,t$_{2}$],(t$_{2}$,t$_{3}$].... dove t$_{k}$ è l'istante di rilascio o scadenza per qualche job, in ciascuno dei quali l'insieme dei job attivi è differenze. Considero X$_{k}$ l'insieme dei job attivi in (t$_{k}$,t$_{k+1}$] e $\Delta_k$ la loro densità:\\ $\sum\limits_{i} e_i$ =  $\sum\limits_{j = 1}^{l} (t_{j+1} - t_j)$ $\cdot$ $\sum\limits_{J_{k} \in X_{i}} \frac{e_k}{d_k - r_k}$ $\leq$ $\sum\limits_{j = 1}^{l} \Delta_{j}(t_{j+1} - t_j)$ $\leq$ t-t'. Vedo la somma di e$_{i}$ come la densità per quell'intervallo moltiplicata per la lunghezza dell'intervallo. Ma il risultato è in contraddizione col fatto che qualcuno ha mancato la scadenza. esempio: \\
Considero job aperiodici J$_{1}$=(r=0, e=1,d=2), J$_{2}$=(r=0.5, e=1,d=2.5), J$_{3}$=(r=1, e=1,d=3)\\
\begin{table}
\begin{tabular}{||c c c||}
\hline\hline
intervalli & job attivi & densità\\
\hline
(0, 0.5] & J$_{1}$ & 0.5\\
\hline
(0.5,1] & J$_{1}$J$_{2}$ & 1.0\\
\hline
(1,2] & J$_{1}$J$_{2}$J$_{3}$ & 1.5\\
\hline
(2,2.5] & J$_{2}$J$_{3}$ & 1.0\\
\hline
(2.5,3] & J$_{3}$ & 0.5
\end{tabular}
\end{table}
Nell'intervallo (1,2] la densità totale è $>$ 1, quindi il teorema non si applica. Schedulabilità con EDF? Sì, il teorema è solo sufficiente: metto J$_{1}$ in (0,1], J$_{2}$ in (1,2] e J$_{3}$ in (2,3] ed ottengo la mia schedulazione.
\section{Controllo d'accesso alle risorse condivise}
Sono partito da modello di carico nel sistema in cui tutti i job erano semplificati, task rilasciavano i job in maniera regolare e tutti i job erano indipendenti ed interrompibili. Mano a mano rilassato queste ipotesi, estendendo il modello. Continuo ad avere singolo processore, sciolgo vincolo di indipendenza dei job nel senso delle risorse condivise. Risorse condivise: accedervi significa vietare a qualunque altro job l'accesso finché il lavoro non è concluso.\\ Nel modello dico che esistono una serie di risorse riciclabili R$_{1}$, R$_{2}$,...., R$_{\rho}$ e ciascuna risorsa R$_{i}$ ha $\nu_{i}$ unità di risorsa indistinguibili assegnabili, non posso assegnare la stessa unità di risorsa a più job ma più job può acquisire più unità di risorsa.\\ Se R$_{i}$ ha un numero $\infty$ unità di risorsa non vale la pena considerarla nel modello,  considero quindi $\nu_{i}$ sempre finito.\\ esempi: semafori, mutex, spin lock, stampanti erc..., si parla di risorse passive: l'unica cosa che conta è che siano disponibili, non sono importanti le loro caratteristiche interne.\\ Come modello una risorsa R che può essere utilizzata da un numero finito di job n $>$ 1: R ha $\nu$ unità esclusive, ovvero nessun job può ottenere più di 1 unità. \\ Come modello invece risorsa R che ha una intrinseca dimensione finita (es una memoria): capisco qual'è l'unità di assegnazione della memoria, ad esempio un pagina di memoria, e faccio corrispondere a $\nu$ il più piccolo blocco di risorsa assegnabile.
\subsection{Richieste e rilasci di risorse}
Un jbo che deve acquisire un certo n° $\eta$ di unità della risorsa R$_{i}$ procede ad effettuare la richiesta L(R$_{i}$, $\eta$). La richiesta è atomica: o ottiene tutte  le $\eta$ unità, altrimenti il job è bloccato (la sua esecuzione è sospesa).Termine blocco è giustificato nel contesto: se non posso ottenere la risorsa, vuol dire che un job a priorità minore di me ha la risorsa. Quando job non ha più bisogno della risorsa fa un rilascio U(R$_{i}$, $\eta$).\\ Spesso il controllo di accesso è affidato a primitive software di tipo lock/unlock. Spesso la risorsa R$_{i}$ ha una sola unità disponibile ($\nu_i$ = 1), abbrevio quindi con L(R$_{i}$) ed U(R$_{i}$). È una semplificazione, ama algoritmi che studio sono facilmente adattabili ad un situazione con $\eta$ variabile.\\ Conflitto di risorse: due job hanno un conflitto di risorse se potenzialmente possono chiedere una risorsa dello stesso tipo. Due job si contendono una risorsa se uno dei due richiede una unità di risorsa che è già posseduta dall'altro job.
\subsection{Sezioni critiche}
Si definisce sezione critica un segmento di esecuzione di jon che inizia con L(R$_{i}$, $\eta$) e termina con U(R$_{i}$, $\eta$). Le richieste di risorse di un job possono essere annidate, ma assumiamo che i rilasci sono sempre LIFO.\\ Una sezione critica non contenuta in alcun'altra sezione critica è detta esterna.\\ La notazione [R$_{1}$, $\eta_1$;e$_{1}$[R$_{2}$,$\eta_2$;e$_{2}$]] corrisponde a:\\ L(R$_{i}$, $\eta_1$) L(R$_{2}$, $\eta_2$) U(R$_{2}$, $\eta_2$) U(R$_{1}$, $\eta_1$) rispettivamente la lunghezza di e$_{2}$ è contenuta nella la lunghezza di e$_{1}$ (ovvero nella regione critica di R$_{1}$ viene fatta la richiesta di R$_{2}$). Quando un certo job richiede una certa risorsa? Non c'è l'indicazione, ragiono sul worst case. esempio:\\
schedulazione con EDF con una unità di risorsa (notazione: freccia bassa è richiesta di risorsa, freccia alta è rilascio).\\
\includegraphics[scale=0.3]{images/SERT2410_1.png}\\\
Le inversioni di priorità causata dal possedere la risorsa causa anomalie di schedulazione: se ad esempio riduco la durata della regione critica d T$_{3}$, quindi apparentemente i job di priorità più alta dovrebbero essere favoriti, ma non è così:\\ 
\includegraphics[scale=0.3]{images/SERT2410_2.png}\\
quando job di T$_{3}$ rilascia la risorsa, il job di T$_{1}$ non è ancora stato rilasciato e quindi entra job di T$_{2}$, quindi T$_{1}$ otterrà la ricorsa troppo tardi. Le inversioni di priorità possono causare anomalie di schedulazione, devo tenerne conto nell'analisi di schedulabilità.
\subsection{Controllo d'accesso alle risorse condivise}
Algoritmi per il controllo di accesso sono necessari:
\begin{itemize}
\item Le inversioni di priorità devono essere controllate, altrimenti sarebbero arbitrariamente lunghe.esempio: J$_{3}$ acquisisce risorsa e poi viene bloccato da J$_{1}$ che vuole acquisire risorsa. Ma ora entra job di J$_{2}$ e può essere deciso dallo scheduler di metterlo nel processore, perché a priorità maggiore di J$_{3}$: J$_{2}$ rallenta sia J$_{3}$ che J$_{1}$. Il ritardo che J$_{3}$ infligge a J$_{1}$ non è solo la lunghezza della regione critica fra J$_{3}$ e J$_{1}$ va misurata nel momento in cui nessuno interrompe J$_{3}$, se ci sono processi che interrompono J$_{2}$ a priorità maggiore che prendono il posto di J$_{3}$ non so quanto sarà lungo il blocco di J$_{1}$ (posso avere molteplici job nel mezzo che rallentano). Questo fenomeno si chiama inversione di priorità non controllata.
\item Deadlock: altro grave problema. J$_{2}$ chiede R$_{1}$, J$_{1}$ chiede R$_{2}$. A quel punto J$_{1}$ chiede R$_{1}$ ma è bloccato, J$_{2}$ continua ed ad un certo punto richiede R$_{2}$. Sono in una situazione di deadlock.
\end{itemize}
\subsubsection{Grafi di attesa}
Mutua relazione tra job e risorse è modellabile con grafi di attesa: i nodi dono i job, altri nodi le risorse. Un arco da un nodo di tipo risorsa ad un di tipo job indica che il job ha allocato un certo n° di unità della risorsa. Il viceversa indica che job ha richiesto un certo numero di unità della risorsa ma questa non può essere soddisfatta. Un ciclo del grafo rappresenta un deadlock:\\
\includegraphics[scale=0.3]{images/SERT2410_3.png}
\subsection{Protocollo NPCS}
Il più semplice protocollo di accesso alle risorse condivise, Nonpreemptive Critcial Section: un job avente una risorsa assegnata non può essere interrotto.\\ Questo risolve tutti i problemi, posso avere deadlock? No, solo a condizione che il job non si auto-sospenda quando ha la risorsa: se job ottiene risorsa e non può essere interrotto non può esserci deadlock, job di priorità superiore non potrà richiedere altra risorsa perché non potrà andare in esecuzione. Se job si auto-sospende tutto il discorso cade: processore è libero e qualcuno può essere schedulato, richiedere una risorsa ed alla fine causare un deadlock.\\ esempio precedente,  schedulazione con NPCS:\\
\includegraphics[scale=0.3]{images/SERT2410_4.png}\\
Non ci sono deadlock e non c'è inversione di priorità incontrollata: al massimo J$_{1}$ sarà bloccato da J$_{3}$ per una durata pari alla regione critica.
\subsubsection{Tempo di blocco per conflitto di risorse}
Sia b$_{i}$(rc) il tempo di blocco dovuto ad un conflitto di risorse. Per NPCS con task a priorità fissa T$_{1}$,....,T$_{n}$:\\
b$_{i}$(rc) = $\underset{i+1 \leq k \leq n}{max}$(c$_{k}$), dove c$_{k}$ è il tempo di esecuzione della più lunga sezione critica di T$_{k}$. Misuro il ritardo che subisce T$_{i}$, i job di priorità superiore non mi danno blocchi, se io voglio una risorsa e la trovo bloccata è per via di job a priorità minore, quelli a priorità superiore non mi fanno neanche entrare nel processore; questo in un modello a singolo processore e senza auto-sospensione.\\ Potrei subire un ritardo perché uno dei job a priorità inferiore alla mia è dentro la regione critica e quindi non può essere interrotto secondo NPCS.\\ Blocco per conflitto di risorse in NPCS è dovuto al fatto che un job a priorità inferiore è dentro la sezione critica.\\ Formula per b$_{i}$(cs) con schedulazione EDF, teorema di Baker: un job J$_{i}$ può essere bloccato da J$_{j}$ solo se d$_{i}$ $<$ d$_{j}$ e r$_{i}$ $>$ r$_{j}$, ossia D$_{i}$ $<$ D$_{j}$.\\ Quindi b$_{i}$(rc) = max\{c$_{k}$: k tale che D$_{k}$ $>$ D$_{i}$\}.\\ Limite del protocollo NPCS: un job può essere bloccato da un job a priorità inferiore anche quanto non ci sono contese o conflitti su alcune risorse. Svantaggioso, quindi si cerca di evitar questo protocollo. D'altra parte, il protocollo è molto diffuso perché è semplice da implementare, non richiede dati sull'uso delle risorse dei job e può essere usato sia per sistemi a priorità fissa che dinamica.
\subsection{Protocollo priority-inheritance}
Protocollo adatto ad ogni scheduler priority-driven, non si basa sui tempi di esecuzione dei job e riesce ad evitare il fenomeno dell'inversione di priorità incontrollata.\\ Idea: cambiare le priorità se esistono delle contese sulle risorse per evitare che un job blocca un altro job di priorità più alta sia rallentato da job di priorità intermedi fra i due. esempio di prima: quando J$_{1}$ richiede la risorsa, poi J$_{3}$ torna normalmente in esecuzione, poi arriva J$_{2}$ che rallenterebbe J$_{3}$, ma ora il fatto che J$_{3}$ sta bloccando J$_{1}$ al sua priorità sarà innalzata fino a quella di J$_{1}$. In questo modo evito che si possano inserire job di priorità intermedia.\\ In pratica: i job sono schedulati in modo interrompibile secondo la loro priorità corrente. inizialmente la priorità corrente $\pi$(t) di un job J rilasciato al tempo t è quella assegnata dall'algoritmo di schedulazione.\\ Quando un job J richiede una risorsa R al tempo t:
\begin{itemize}
\item Se R è disponibile, R vine assegnata a J
\item Se R non è disponibile, J è sospeso (bloccato)
\end{itemize}
Quando un job J viene bloccato a causa di una contesa su una risorsa R, il job J$_{l}$ che blocca J eredita la priorità corrente $\pi$(t)  di J finché non rilascia R; a quel punto, la priorità corrente di J$_{l}$ torna ad essere la priorità $\pi_{l}$(t') che aveva al momento t' in cui aveva acquisito la risorsa R.\\ esempio: schedulazione a priorità fissa con priority-inheritance, qui supponiamo che la risorsa venga chiesta dopo un'unità di tempo dal rilascio.\\
\includegraphics[scale=0.3]{images/SERT2410_5}\\
Limiti:
\begin{itemize}
\item Non evita i deadlock
\item Introduce nuovi casi di blocco: un job a priorità corrente $\pi$(t) può bloccare ogni job con priorità assegnata minore di $\pi$(t).
\item Non riduce i tempi di blocco dovuti ai conflitti sulle risorse al minimo teorico possibile. esempio: ho un job a priorità alta: il job ha sotto di se molti job a priorità inferiore, usa molte risorse annidate. Se tutte le risorse sono assegnate: se accede ad un certo numero v di risorse ed ha conflitti con k job di priorità inferiore assegnata può bloccare per un min(k,v) volte.\\ Devo dimensionare il sistema in modo molto pessimista
\end{itemize}
\subsection{Protocollo priority-ceiling}
Adatto a scheduler con priorità fissa.È basato sulle richieste di risorse dei job prefissati, evita inoltre tutti e due i problemi.\\ Idea: associare ad ogni risorsa R il valore priority ceiling $\lceil\rceil$(R) pari alla massima priorità dei job che fanno uso di R. Dato che sa quale task userà quale risorsa, ad ogni risorsa è possibile associare il priority ceiling. Inoltre, il protocollo definisce il current priority ceiling $\lceil\rceil$'(R) che è apri a:
\begin{itemize}
\item La massima priorità $\lceil\rceil$(R) fra tutte le risorse del sistema correntemente in uso al tempo t
\item al valore convenzionale $\Omega$ di priorità  inferiore a quella di qualunque task se nessuna risorsa è in uso.
\end{itemize}
Confrontando le priorità, $\pi$(t) $>$ $\pi'$(t) significa che $\pi$(t) ha maggiore priorità di $\pi'$(t); così se a valore inferiore corrisponde priorità superiore, $\pi$(t) = 1 e $\pi'$(t) = 2 implica che $\pi$(t) $>$ $\pi'$(t).\\ Regola di schedulazione: job schedulati in modo interrompibile secondo la loro priorità corrente.\\ Se al tempo t un job J con una certa priorità corrente $\pi$(t) richiede una risorsa R, R è allocata a J sole se è disponibile d inoltre:
\begin{itemize}
\item $\pi$(t) $>$ $\lceil\rceil$(t)
\item J possiede una risorsa il cui priority ceiling è uguale a $\lceil\rceil'$(t)
\item altrimenti J è bloccato.
\end{itemize}
Se J$_{l}$ blocca J, J$_{l}$ eredità la priorità corrente $\pi$(t) di J finché J$_{l}$ non rilascia l'ultima risorsa R tale che $\lceil\rceil$(R) $\geq$ $\pi$(t); a quel punto la priorità di J$_{l}$ torna ad essere la priorità $\pi_{l}$(t') che aveva al momento t' in cui aveva acquisito la risorsa R.\\ esempio:\\
\includegraphics[scale=0.3]{images/SERT2410_6.png}\\
Stabilisco prima i priority ceiling delle risorse. Ho un blocco: il motivo per cui J$_{4}$ non può continuare perché è bloccato da J$_{5}$, quindi J$_{5}$ eredita la priorità di J$_{4}$.\\ In quanti casi diversi un job J$_{l}$ può bloccare un job J$_{h}$ con priorità $\pi{l}$ $<$ $\pi{h}$:
\begin{itemize}
\item Blocco diretto: J$_{h}$ richiede una risorsa R assegnata a J$_{l}$.
\item Blocco dovuto a priority-inheritance: la priorità corrente di J$_{l}$ è maggiore di quella di J$_{h}$, perché J$_{l}$ sta bloccando direttamente un job che ha priorità maggiore di J$_{h}$.
\item Blocco dovuto al priority ceiling (o avoidance blocking): J$_{h}$ ha richiesto una risorsa R ma J$_{l}$ possiede un'altra risorsa R' tale che $\lceil\rceil$(R') $\geq$ $\pi_{h}$.
\end{itemize}
I deadlock possono essere evitati se tutti i job acquisiscono le risorse annidate rispettando un unico ordinamento globale delle risorse; metodo principale usato nei sistemi operativi.\\ I priority ceiling non definiscono un ordinamento globale delle risorse, bensì parziale ma che basta ad evitare i deadlock. esempio:\\
\includegraphics[scale=0.3]{images/SERT2410_7.png}\\
Sono esposto ad un deadlock, ma con priority ceiling non avverrà: al tempo 2.5 J$_{2}$ richiede R$_{2}$, ma la richiesta viene rifiutata anche se R$_{2}$ è libera, così si evita un possibile deadlock con J$_{3}$. I job con priorità corrente maggiore di $\lceil\rceil'$(t) possono acquisire risorse sezna rischiare deadlock con le risorse già assegnate.\\ Posso avere molti job e risorse: ho J$_{1}$, che usa R$_{1}$,R$_{2}$, poi ho J$_{2}$ che usa R$_{3}$,R$_{4}$, userà anche R$_{1}$,R$_{2}$ ma non è un problema, perché il priority ceiling di R$_{1}$,R$_{2}$ è quelli di J$_{1}$ e così via per i vari livelli:\\
$\lceil\rceil$(R$_{1}$) = $\lceil\rceil$(R$_{2}$) = $\pi_{1}$\\
$\lceil\rceil$(R$_{3}$) = $\lceil\rceil$(R$_{4}$) = $\pi_{2}$.
e così via \\ Suppongo che $\lceil\rceil'$(t$_{0}$) sia ad un certo livello $\pi_{k}$: questo vuol dire che sono assegnate nel sistema solo risorse al di sotto di questo livello. Se al tempo t$_{0}$ un job richiede un risorsa e la sua priorità $\pi_{J}$(t$_{0}$) $>$ $\lceil\rceil'$(t$_{0}$):
\begin{itemize}
\item J non richiederà mai alcuna risorsa già assegnata al tempo t$_{0}$. Quindi non avrò nessun deadlock con le risorse già assegnate
\item Nessun job con priorità maggiore di $\pi_{j}$(t$_{0}$) chiederà alcuna risorsa già assegnata la tempo t$_{0}$ , quindi nessun job che già possiede una risorsa al tempo t$_{0}$ portà interrompere J e richiedere R.
\end{itemize}
Il risultato è che il protocollo priority-ceiling evita i deadlock.
\subsubsection{Proprietà del protocollo priority-ceiling}
Come visto sopra:
\begin{itemize}
\item al tempo t un job possiede tutte le risorse assegnate aventi priority ceiling uguale a $\lceil\rceil'$(t).
\item se un job sta per ottenere un risorsa $\pi$(t) $>$ $\lceil\rceil'$(t), nessun job di priorità uguale o superiore ha richiesto o richiederà le risorse già assegnate
\item Se un job sta per ottenere una risorsa $\pi$(t) = $\lceil\rceil'$(t), il job è il possessore di tutte le risorse assegnate aventi priority ceiling uguale a $\lceil\rceil'$(t).
\item i deadlock sono dunque evitati: priorità assegnate all risorse definiscono in un certo modo un ordinamento non totale tra le risorse.
\end{itemize}
Se al tempo t$_{0}$ un job J richiede una risorsa R e $\pi$(t$_{0}$) $>$ $\lceil\rceil'$(t): 
\begin{itemize}
\item J non richiederà mai alcuna risorsa già assegnata aò tempo t$_{0}$
\item Nessun job a priorità $\geq$ $\pi$(t${0}$) chiederà una risorsa già assegnata al tempo t$_{0}$.
\end{itemize}
Quindi priority ceiling evita i deadlock.\\ Non basta questa proprietà per giustificare la complessità di priority ceiling: basterebbe programmare bene i job nel sistema per evitare i deadlock.\\ In priority-ceiling, ho 3 blocchi possibili: blocco diretto, priority-inheritance, priority-ceiling.\\ C'è un teorema:\\ utilizzando il protocollo priority-ceiling un job può essere bloccato al massimo per la durata di una sezione critica.Teorema vuol dire che su un job subisce blocco a causa di una risorsa condivisa lo farà una volta sola, non subirà blocchi consecutivi. Inoltre blocco non sarà per un tempo costituito da annidamento di diverse sezioni critiche, ma per un tempo pari a solo la durata di una sezione critica.2 proprietà:
\begin{itemize}
\item Se un job viene bloccato, è bloccato da un solo job
\item Non esiste blocco transitivo: non si verifica mai il caso J$_{3}$ blocca J$_{2}$ e J$_{2}$ blocca J$_{1}$.
\end{itemize}
Unicità del job bloccante:\\ ho 3 job di priorità variabili.
\includegraphics[scale=0.3]{images/SERT2910_1.png}\\
J$_{h}$ è bloccato sia da J$_{m}$ che da J$_{l}$. Perché non può avvenire in priority ceiling:\\ $\pi_{h}$ $>$ $\pi_{m}$ $>$ $\pi_{l}$ $\Rightarrow$ $\lceil\rceil$(R$_{1}$) $\geq$ $\pi_{h}$ e $\lceil1rceil$(R$_{2}$) $\geq$ $\pi_{h}$.\\ Ora: $\lceil\rceil'$(t$_{0}$) $\geq$ $\lceil\rceil$(R$_{1}$) $\geq$ $\pi_{h}$. Il requisito per l'allocazione a t$_{0}$ deve essere $\pi_{m}$ $>$ $\lceil\rceil$(R$_{1}$) $\geq$ $\pi_{h}$. Ma questo non è verificato e quindi il priority ceiling nega l'assegnazione della risorsa a J$_{m}$.\\ Se J$_{m}$ acquisisce una risorsa a t$_{0}$, nessun job con priorità maggiore o uguale può richiedete una risorsa già in uso a t$_{0}$.\\ Impossibilità del blocco transitivo:\\
\includegraphics[scale=0.3]{images/SERT2910_2.png}\\
J$_{l}$ sta bloccando J$_{m}$ e J$_{m}$ sta bloccando J$_{h}$. Perché non può verificarsi:\\ $\pi_{h}$ $>$ $\pi_{m}$ $\pi_{l}$ $\Rightarrow$ $\lceil\rceil$(R$_{1}$) $\geq$ $\pi_{m}$ e $\lceil\rceil$(R$_{2}$) $\geq$ $\pi_{h}$.\\ Quindi $\lceil\rceil'$(t$\_{0}$) $\geq$ $\lceil\rceil$(R$\_{1}$) $\geq$ $\lceil\rceil'$t$_{0}$; quindi l'allocazione non può avvenire.\\
\subsubsection{Tempo di blocco per conflitto di risorse}
È il massimo tempo di ritardo un job del task T$\_{i}$ causato da un conflitto di risorse.\\ Come faccio per calcolarlo: ho 3 tipi di blocco, quindi devo calcolarlo per tutti e 3  tipi, mi il teorema mi dice che il job può essere bloccato per al massimo una sezione critica, quindi considero il massimo.esempio:\\ J$_{1}$:[R$_{1}$;0.8], J$_{2}$, J$_{3}$:[R$_{2}$;0.2], J$_{4}$:[R$_{1}$;1].\\ 
\includegraphics[scale=0.3]{images/SERT2910_3.png}\\
J$_{4}$ può bloccare direttamente J$_{1}$ per 1 unità di tempo $\Rightarrow$ b$_{1}$(rc) = 1. J$_{4}$ può bloccare anche J$_{2}$ e J$_{3}$, quando acquisisce R$_{1}$ $\Rightarrow$ b$_{2}$(rc) = b$_{3}$(rc) = 1: può bloccare per priority inheritance. Sto facendo analisi pessimista: J$_{4}$ chiede la risorsa e subito dopo la chiede J$_{1}$. Il job per J$_{4}$ è b$_{4}$(rc) = 0, perché il job di priorità più bassa.\\ Per esempi più complessi, conviene avere un algoritmo automatico per derivare i tempi di blocco:
\includegraphics[scale=0.3]{images/SERT2910_4.png}
\begin{itemize}
\item Costruisco una tabella dei tempi di blocco diretti. Su entrambe le colonne avrò i nomi dei job, ciascuna componente rappresenta il tempo di blocco diretto che il job della colonna fa subire al job della riga.\\ Le righe hanno i 5 job di priorità superiore mentre le colonne i 5 di priorità inferiore
\item Metto asterisco sugli elementi della "diagonale", ovvero le righe e colonne con lo stesso job, so che sotto la diagonale il blocco non può avvenire, quindi avrò valore 0.
\item Riempio le componenti sopra gli asterischi: vedo chi è in conflitto sulle varie risorse.
\end{itemize}
Posso derivare in maniera automatica la tabella per i blocchi dovuti all'inheritcance: 
\includegraphics[scale=0.3]{images/SERT2910_5.png}
\\avviene in caso di contesa, quindi quando un job nel blocca un altro viene trasferita la priorità. J$_{3}$ blocca J$_{1}$ per 6 unità di tempo. Ma allora il job di priorità intermedia può essere bloccato per 6 unità di tempo, quindi il 6 scende di una posizione nella tabella. Blocco tra J$_{2}$ e J$_{4}$, questo danneggia i job di priorità intermedia, ovvero J$_{3}$, il 5 scende fino alla riga di J$_{3}$.\\ J$_{6}$: blocca per inheritance anche tutti i job di priorità intermedia tra lui e J$_{1}$, e quindi tutti gli altri. Voci scendono sempre fino all'asterisco. Ad un certo punto, trovo che J$_{6}$ sta bloccando direttamente anche J$_{3}$, quindi per inheritance J$_{3}$ è bloccato per 2 unità di tempo, ma poi J$_{4}$ sarebbe bloccato per 2 unità di tempo a causa della contesa con J$_{1}$ ma anche per 4 unità per via della contesa con J$_{3}$. Devo considerare il worst case: ora è 4, quindi è il 4 a propagarsi verso il basso.\\ Infine ho la tabella per il blocco per priority ceiling:\\
\includegraphics[scale=0.3]{images/SERT2910_6.png}\\
Questo diventava simile al blocco per inheritance: J$_{4}$ può essre danneggiato da J$_{6}$ perché J$_{6}$ richiede risorsa che innalza il priority ceiling, caso peggiore è il max fra la lunghezza della regione critica fra R$_{1}$ ed R$_{2}$ (per J$_{6}$). Siccome J$_{5}$ non richiede risorse, manca il valore perché J$_{5}$ non può mai essere bloccato in quanto non richiede risorse.\\ A questo punto posso definire B$_{i}$(r,c) = max\{B$_{d}$(j, c): 1 $\leq$ j $\leq$ r-1\}.\\ Se le priorità dei job sono tutte diverse, B$_{c}$ = B$_{i}$, tranne che per i job che non utilizzano risorse.\\ b$_{i}$(rc) = max$_{k}${B$_{d}$ B$_{i}$(j, k), B$_{c}$(i, k)}: considero il valore massimo per ciascuna riga, perché priority ceiling mi dice che blocco al massimo 1 volta. Cosa cambiare se i job possono avere priorità identiche?
\subsection{Schedulabilità con priority ceiling}
Ho i tempi di blocco, li considero tra i tempi di blocco totali dei task, lo faccio task per task:\\
b$_{i}$ = b$_{i}$(ss) + (K$_{i}$ + 1)$\cdot$b$_{i}$(np) + (K$_{i}$ + 1)$\cdot$b$_{i}$(rc), con K$_{i}$ massimo numero di auto-sospensioni di un job del task T$_{i}$. Il fatto dell'unicità del job bloccante vale solo se i job non si auto-sospendono. Devo anche tenerne conto all'overhead su cambi di contesto: e$_{i}$' = e$_{i}$ + 2$\cdot$(K$_{i}$ + 1)$\cdot$CS + 2$\cdot$(K$_{i}$ + 1)$\cdot$CS, ma solo se il job usa le risorse condivise.
\subsection{Protocollo stack-based priority-ceiling}
Baker, 1991. È una semplificazione del protocollo priority-ceiling, motivato da un esigenza particolare: la condivisione di un unico stack da parte dei job. Usare uno stack unico comporta problemi: stack è LIFO, ogni volta che arriva un job sopra, interrompe quello sotto. Se un job arriva e richiede una risorsa, ma poi arriva una altro job che interrompe: comincia ad usare lo stack, in una zona contigua a quel job interrotto. Quando il job si conclude, toglie dallo stack tutte le informazioni che aveva introdotto. Ma se il jbo richiede la stessa risorsa del job che ha interrotto: per priority ceiling deve tornare in esecuzione il job interrotto. Probelma: il job non può togliere le info dallo stack ed ora il job che torna si trova una parte dello stack occupato.\\ Questo porta al fatto che nessun job deve bloccare o auto-sospendersi.\\ Per ogni risorsa R, $\lceil\rceil$(R) definito come nel protocollo priority-ceiling. C'è regola di aggiornamento che  è la stessa. \\ Regola di schedulazione: non appena rilasciato, un job J con priorità maggiore assegnata $\pi$ non può essere eseguito finché non è vera la condizione $\pi$ $\leq$ $\lceil\rceil$'(t). I job eseguibili sono schedulati in modo interrompibile in accordo alle priorità assegnate.Non c'è priority inheritance\\ Regola di allocazione: quando un job richiede una risorsa, la richiesta è soddisfatta.\\ Un job di priorità alta può interrompere un job di priorità bassa, e quest'ultimo non può tornare in esecuzione finché il primo non ha finito. Potrebbe farlo se il job bloccasse, ma questo non succede perché risorsa è libera o se si auto-sospendesse, ma qui questo non avviene. Quando un job comincia l'esecuzione tutte le risorse di cui ha bisogno sono libere: difatti inizia solo se la sua priorità diviene uguale o maggiore del priority ceiling del sistema.\\ Non ci sono mai deadlock: le risorse sono sempre libere quando le richiedo. Job non i auto-sospendono: il controllo d'accesso è effettuato solo al rilascio di un job e assume che il job non venga sospeso.\\ esempio di schedulazione:\\
\includegraphics[scale=0.3]{images/SERT2910_7.png}
\subsection{Ceiling priority}
Usato nel Real-time System Annex di Ada95: linguaggio molto usato negli USA. È stato definito dal governo per lo sviluppo del sw in tutte le commesse militari.\\ Regola di schedulazione:
\begin{itemize}
\item Se un job non possiede alcuna risorsa, la sua priorità è quella rassegata dallo scheduler
\item Se un job possiede una risorsa, la sua priorità è uguale al massimo priority ceiling di tutte le risorsa assegnate al job.
\end{itemize}
Job con priorità identica sono schedulati in modo FIFO.\\ Regola di allocazione: quando un job richiede una risorsa la ottiene. Risorsa è sempre libera: se fosse occupata, il job che la sta usando avrebbe priorità almeno uguale a quello che la sta richiedendo.\\ Differenza fra stack-based e ceiling priority? Senza auto-sospensione le schedulazioni prodotte sono identiche. Però in ceiling-priority è possibile modificare le regole per permettere auto-sospensione.\\ Confronto tra i protocolli: Teorema(Baker, 1911): I tempi di blocco massimi b$_{i}$(rc) dovuti ai conflitti di risorse per priority-ceiling e per stack-based priority-ceiling sono identici. Quindi scheduler che usano stack-based o ceiling-priority sono più semplici ed efficienti, in più hanno meno context-switch. Però i cambi di prioirtà dinamiche sono meno frequenti in priority-ceiling, che ci sono solo in caso di contesa.\\ Trade off, ma spesso vincono gli ullimi due
\subsection{Controllo d'accesso per job con auto-sospensione}
I vari protocolli vanno adattati all'auto-sospensione:
\begin{itemize}
\item NPCS: non è possibile auto-sospendersi in una sezione critica
\item Priority-inheritance: se un job J è bloccato su una risorsa posseduta da un job J' auto-sospeso, la priorità dinamica di J' è aggiornata solo se $\pi$(t) $>$ $\pi$(t')
\item Priority-ceiling: non funziona più unicità del blocco
\item Stack-based: non esiste
\item Ceiling-priority; se un job si auto-sospende in una sezione critica, nessun job di priorità inferiore o uguale può essere eseguito. È come se nullificasse i vantaggi dell'auto-sospensione nelle sezioni critiche
\end{itemize}
esempio: auto-sospensione\\
\includegraphics[scale=0.3]{images/SERT2910_8.png}\\
Tempi di blocco per autosospensione
\begin{itemize}
\item NPCS: b$_{i}$ = b$_{i}$(ss) + (K$_{i}$ + 1)$\cdot$max\{b$_{i}$(np), b$_{i}$(rc)\}
\item priority ceiling e ceiling priority: b$_{i}$ = b$_{i}$(ss) + (K$_{i}$ + 1)$\cdot$ (b$_{i}$(np) + b$_{i}$(rc)). Qui i tempi di blocco b$_{i}$(rc) vanno calcolati anche pensando che mentre sono in sezione critica posso auto-sospendermi, quindi debo considerare anche il tempo massimo di auto sospensione e moltiplicare per il numero di volte in cui mi auto-sospendo.
\end{itemize}
\subsection{Priorità dinamica}
È possibile applicare i protocolli priority-ceiling e ceiling-priority a sistemi con priorità dinamica. Il valore del priority ceiling di una risorsa non è costante, ma dipende dalla priorità dinamica che potenzialmente fanno uso della risorsa. Il priority ceiling può cambiare, ad esempio con EDF ogni volta che rilascio un nuovo job, questo ha una prioirtà dovuta alla scadenza assoluta che fa cambiare i valori di priorità di tutti ti job del sistema, quindi i, pririty ceiling delle risorse e quindi il current priority ceiling del sistema. Molto poco applicabile nella realtà. Quando schedulo con algoritmi a priorità dinamica uso o NPCS o priority inheritance o altri sistemi per evitare deadlock come allocare risorse in tempi predefiniti.\\ esempio di priority ceiling con EDF:\\
\includegraphics[scale=0.3]{images/SERT2910_9.png}
\subsection{Accesso alle risorse di job aperiodici}
Problema: un server procrastinabile che sta eseguendo un job aperiodico esaurisce il budeget mentre il job è in sezione critica:
\begin{itemize}
\item Esecuzione all'interno della sezione critica rende il server non interrombilile anche se il budgrt finisce
\item Se ho accumulato ritardo, rifornisco meno budget.
\item Problema di schedulabilità e ritardi aggiuntivi, devo aggiungere anche la lunghezza della sezione critica dei job aperiodici. Questo comporta difficoltà nello studio, ma è modellabile
\end{itemize}
\section{Real-time su multiprocessore}
Ho rimosso man mano le limitazioni complicando il modello, rilasso l'ipotesi di avere un singolo processore(ultima limitazione rimasta).\\ Sistema multiprocessore ha 2 o più processori, ciascuno può eseguire job in maniera indipendente.\\ Processori possono essere dello stesso tipo o di tipo diverso:
\begin{itemize}
\item diversi microprocessori mutli-core
\item diverse schede di rete
\item diverse schede PCI con controllori DMA
\end{itemize}
In un certo senso, per cercare di modellare il sistema avrò $\mu$ tipi di processori quanti processori m$_{i}$ ci sono per i $\leq$ i $\leq$ $\mu$, anche su quali tipi di processore si può eseguire ciascun job. Semplifico supponendo che tutti i processori sono dello stesso tipo.\\ Ci si è resi conto molto presto che aggiungere processori complicava le cose: molto più complesso che schedulare su singolo processore.
\subsection{Sistemi statici}
Un sistema real-time è statico se ciascun job è assegnato perennemente ad uno specifico precessore. Partiziono i task nel sistema tale che ciascun job o task è eseguito forzatamente da uno specifico precessore: posso effettuare la schedulazione normalmente, ciascuno ha una lista di job e mi riconduco al caso del singolo processore (non proprio così).\\ 2 tipi di sistemi statici:
\begin{itemize}
\item L'assegnazione dei job è effettuata manualmente dal progettista una volta per tutte in fase di progettazione del sistema. Problema: devo conoscere tutti i parametri dei task, non posso gestire nuovi task che arrivano a run time
\item L'insieme dei task è assegnato ad uno specifico processore dal SO (o scheduler) durante la fase di creazione del task. Scheduler partizionati.
\end{itemize}
In entrambi i casi, lo scheduler non decide su quale processore sarà eseguito un job appena rilasciato.\\ esempio di schedulazione:\\
\includegraphics[scale=0.3]{images/SERT3010_1.png}\\ I job hanno delle dipendenze: questo fa capire che il sistema non è analogo a tanti sistemi mono-processore, non ci sarebbero vincoli fra job su processori diversi. Ogni scheduler decide i job assegnati ai processori, ma i vincoli di dipendenza sono grosse complicazioni.\\ Vantaggi:
\begin{itemize}
\item Si può analizzare la schedulabilità su  ciascun processore usando i risultati teorici validi per il caso mono-processore
\item Se un job va in overrun (impiega più tempo del previsto) può ritardare l'esecuzione dei soli task che sono sul suo stesso processore (se job sono indipendenti tra di loro)
\item Se un job è interrotto, siccome il sistema è statico riprenderà l'esecuzione sullo steso processore, evito i costi dovuti alla migrazione
\item La coda di esecuzione è relativa al singolo processore ed è quindi più piccola
\end{itemize}
\subsection{Sistemi dinamici}
Un sistema real-time è dinamico se lo scheduler assegna dinamicamente un job ad un qualunque processore disponibile
3 varianti:
\begin{itemize}
\item Con job interrompibili
\item Con job interrompibili e non migrabili: anche se interrotto, job è salvato in una struttura locale del processore e potrà recuperare l'esecuzione solo si quel processore
\item COn job interrompibili e migrabili: job può essere migrato se interrotto, ha un costo
\end{itemize}
Una algoritmo di schedulazione per un sistema dinamico è globale perché stabilisce quale processore eseguirà quale job. \\esempio:\\
1° caso: job interrompibili e migrabili:\\
\includegraphics[scale=0.3]{images/SERT3010_2.png}\\
2° caso, job non interrompibili:
\includegraphics[scale=0.3]{images/SERT3010_3.png}\\ Il momento in cui l'ultimo job completa il lavoro è uguale nel caso dei job migrabili a quello della schedulazione nel sistema statico $\Rightarrow$ anomalia di schedulazione.\\ Vantaggi:
\begin{itemize}
\item Hanno tipicamente meno cambi di contesto: quando viene rilasciato un job, in un sistema statico se c'è in esecuzione job di priorità minore devo interrompere e fare context swtich. In sistema dinamico posso avere processori free, quindi metto in esecuzione lì.
\item Se un job esegue per meno tempo di quello che è il suo worst case, il tempo liberato sul processore può essere utilizzato potenzialmente da tutti i task de sistema (nel caso del sistema statico è usato solo da quelli locali al processore).
\item Se un job impiega più tempo (overrun) la probabilità che questo comporti la mancanza di una op più scadenze è minore. Non è contrapposizione con 2: sistema può usare tutti i processori per cercare di porre rimedio al tempo in più per cui il job ha eseguito
\item Per ogni task del sistema che è creato a run-time, assegnazione e bilanciamento del carico sono "automatici" e determinati dall'algoritmo di schedulazione globale
\end{itemize}
\subsection{Algoritmi di schedulazione multiprocessore}
Gli algoritmi clock-driven sono in generale utilizzabili senza problemi, infatti la schedulazione avviene offline e validata una volta per tutte.Metodo però poco flessibile, ma non è immediato applicare algoritmi prioirty-driven, devo studiare bene come fare: devo risolvere diversi problemi
\begin{itemize}
\item Efficienza degli algoritmi, effetto Dhall
\item Predicibilità del sistema
\item Test di schedulabilità.
\end{itemize}
\subsection{Effetto Dhall}
Teorema (Dhall \& Liu): Per ogni numero di processori m $\geq$ 2, esistono insieme di task con utilizzazione bassa che non sono schedulabili con RM, DM o EDF.\\ Considero T$_{1}$=81, 2$\epsilon$), T$_{2}$=(1,2$\epsilon$,....,T$_{m}$=(1,2$\epsilon$), T$_{m+1}$?(1+$\epsilon$, 1). Utilizzazione globale = 2$\epsilon$ $\cdot$ m + $\frac{1}{1+ \epsilon}$ $\rightarrow$ 1 se $\epsilon$ $\rightarrow$ 0. Basterebbe uno o al massimo due processori per eseguire tutti questi task.\\ Ho una schedulazione fattibile: esempio per m=2\\
\includegraphics[scale=0.3]{images/SERT3010_4.png}\\
Problema è che la schedulazione non è RM né DM né EDF: se schedulo con EDF vincono le scadenze assolute, quando tutti i job vengono rilasciati due job hanno priorità sugli altri, quindi quando i processori si liberano uno dei job manca la scadenza; stesso vale per RM e DM.\\ Questo risultato ha scoraggiato per tanti anni la ricerca su sistemi multiprocessore real-time, riprende quando siatemi multiprocessore si sono largamente diffusi da costringere a riguardare il problema: 2001, effetto Dhall esiste solo con sistemi di task in cui uno dei task ha un utilizzazione molto alta. Se task hanno utilizzazione non uguale ad 1 non si verifica l'effetto Dhall.
\subsection{Anomalie di schedulazione}
Comportamene di un algoritmo tale che, a fronte di variazione apparentemente vantaggiose dei parametri si hanno dei peggioramenti delle prestazioni. Esempi:
\begin{itemize}
\item Aumentano il periodo di un task
\item Aumento n° processori
\item Diminuisco il tempo di esecuzione di un task
\end{itemize}
Anomalie di schedulazione si verificano se task sono non interrompibili o indipendenti, nei sistemi uni-processore.\\ Nei sistemi multiprocessore? Mi metto nelle ipotesi che non ci siano vincoli di dipendenza:\\
\begin{itemize}
\item Sistema statico, job non interrompili: posso avere anomalie
\item Sistema statico, interrompibili: non ho anomalie
\item Sistema dinamico, job non interrompibili: posso avere anomalie
\item Sistema dinamico, job interrompibili ma non migrabili: sì
\item Sistema dinamico, job interrompili e migrabili: sì.
\end{itemize}
Perché le anomalie complicano la validazione? Non esiste un worst case a cui ricondursi, bisogna cercare un modo per tenere sotto controllo le anomalie.\\ esempio: anomalie di schedulazione con job non migrabili\\
\includegraphics[scale=0.3]{images/SERT3010_5.png}\\
anomalie di schedulazione con job migrabili:\\
\includegraphics[scale=0.3]{images/SERT3010_6.png}
\subsection{Schedulabilità}
Istanti critici in schedulazioni globali: c'è un teorema che mi dice che usando uno scheduler globale a priorità fissa a livello di task, l'istante in cui un job di un task T$_{i}$ è rilasciato contemporaneamente ai job di tutti i task di priorità superiore T$_{1}$,....,T$_{i-1}$ non è necessariamente un istante critico di T$_{i}$\\ esempio:\\
\includegraphics[scale=0.3]{images/SERT3010_7.png}\\ No ho modo di usare il test di schedulabilità.\\ Fattore di utilizzazione per multiprocessore: (thm) dato un sistema di task periodici con scadenze uguali ai periodi ed m processori, se X è un qualsiasi algoritmo di schedulazione partizionato con priorità fissa a livello di task:\\
U$_{X}$ $\leq$ $\frac{m + 1}{1 + 2^{\frac{1}{m +1}}}$. In pratica: se ad esempio uso RM, che ha su mono processore U$_{X}$ $\simeq$ 0.69, considerandolo partizionato il fattore di utilizzazione è limitato, non può in nessun modo utilizzarlo.\\ Teorema(2001): dato un sistema di task periodici con scadenze implicite ed m processori, sia X:
\begin{itemize}
\item un qualsiasi algoritmo di schedulazione partizionato
\item un qualsiasi algoritmo di schedulazione globale con priorità fissa a livello di job
\end{itemize}
allora per il fattore di utilizzazione di X si ha: U$_{X}$ $\leq$ $\frac{m + 1}{2}$.\\ Man mano che aumento il numero di processori, devo lasciarne sempre di più liberi. Sto quindi lavorando in perdita: se voglio aumentare di un processore il mio sistema, ne devo aggiungere 2 e cos' via...\\ Corollario: nessun algoritmo di schedulazione globale con priorità fissa a livello di job è ottimale su multiprocessore. Non posso sfruttare al 100\% tutti i processori del sistema.\\ esempio:\\
\includegraphics[scale=0.3]{images/SERT3010_8.png}\\ Come si vede nell'esempio, schedulazione non EDF ottimale esiste.\\ Esistono algoritmi ottimali di schedulazione dinamica a livello di job che hanno fattore di utilizzazione pari ad m, esempio LST che però è complicato da implementare. Non esistono algoritmi on-line ottimali se gli istanti di rilascio dei job non sono esattamente prefissati.\\ Classe di algoritmi ottimali su multiprocessore è derivata dall'algoritmo Pfair:
\begin{itemize}
\item basati sul concetto di schedulazione fluida. Ogni task progredisce in modo proporzionale alla sua utilizzazione.
\item tempo diviso in quanti: allo scadere di ogni quanto, lo scheduler assegna i task ai processori in modo che per ogni task T$_{i}$, il lavoro compiuto sia $\lceil \frac{te_i}{p_i}\rceil$ o $\lfloor\frac{te_i}{p_i}\rfloor$.\\ Più è piccolo il quanto di tempo, più mi avvicino ad una schedulazione fluida, come in un SO in cui processi si alternano per quanti piccoli: sembra come se processi facessero progressi contemporaneamente
\end{itemize}
Gli algoritmi dinamici a livello di job sono molto costosi in termini di overhead dello scheduler. quindi non sono adottati.
\subsection{Schedulazione partizionata}
Nei sistemi real-time multiprocessore statici, l'algoritmo di schedulazione è partizionato. Non parlo di algoritmi in cui il progettista fissa i task ai processori, serve descrivere due componenti:
\begin{itemize}
\item Algoritmo che assegna i task ai processori (problema NP hard, non ammette algoritmo ottimale efficiente, tempi esponenziali nell'istanza del problema)
\item Algoritmo che schedula i task su ciascun processore
\end{itemize}
\subsubsection{Allocazione dei task}
Dato un sistema di task periodici,partizionare i task in sottoinsiemi tali che ciascun sottoinsieme può essere schedulato in modo fattibile su un singolo precessore utilizzando un determinato algoritmo do schedulazione.\\Un sistema di n task indipendenti è schedulabile con n processori (purché ciascun task abbia densità inferiore ad 1).\\ Non esiste algoritmo polinomiale che possa capire il più piccolo n° di processori per schedularlo. Gli algoritmi di schedulazione dei task possono solo calcolare soluzioni approssimate (non ottimali):
\begin{itemize}
\item Non riescono ad associare i task ai processori in modo da sfruttarli nel miglior modo possibile
\item Non riescono a determinare schedulabilità fattibili per ogni possibile insieme di task schedulabile
\end{itemize}
Limiti che non sono superabili.\\ Metriche di bontà:
\begin{itemize}
\item Rapporto di approssimazione: è il massimo valore $\frac{m}{m_0}$, dove m è il numero di processori usato dall'algoritmo di allocazione ed m$_{0}$ è  il minimo numero teoricamente necessario, considerando ogni possibile sistema di task. Buono se n° task è piccolo, m$_{0}$ non è facile da determinaste
\item Fattore di accelerazione: quanto è necessario aumentare la velocità di esecuzione degli m$_{0}$ processori per schedulare fattibilmente ogni possibile sistema di task le assegnazioni determinate dall'algoritmo di allocazione.
\item Fattore di utilizzazione: il valore di soglia per cui i sistemi di task con fattore di utilizzazione totale inferiore o uguale sono sempre schedulabilità utilizzando l'algoritmo di allocazione dei task.
\end{itemize}
\subsubsection{RMFF}
Il più semplice (Rate Monotonic First Fit), passi:
\begin{itemize}
\item ordina i task per periodi non decrescentisi T${1}$,...,T${n}$
\item ordina arbitrariamente i processori: P${1}$,...
\item comincia da T${1}$, assegna ciasun task T${i}$ al primo processore P${j}$ tale che l'insieme dei task già assegnati a P${j}$ insieme a T${i}$ risulta ancora schedulabile tramite RM.
\end{itemize}
U${RMFF}$ = m $\cdot$ ($\sqrt[2]{2}$ - 1).\\ Fattore di approssimazione: 2.23, usa un numero di processori che è 2.33 $\cdot$ numero ottimale (più del doppio). Non può essere usato come algoritmo on-line: siccome ordino per periodo non decrescenti, se arriva un nuovo task a run-time devo rifare tutto e quindi anche le assegnazioni, il che è impossibile. Usabile solo se conosco tutti i task in anticipo.
\subsubsection{FFDU}
Passi:
\begin{itemize}
\item ordina i task per periodi non decrescentisi T${1}$,...,T${n}$
\item ordina arbitrariamente i processori: P${1}$,...
\item cominciando da T$_{1}$, assegna ciascun task T$_{i}$ al primo processore P$_{j}$ tale che l'insieme dei task già assegnati a P$_{j}$ insieme a T$_{i}$ risulta ancora schedulabile tramite RM.
\end{itemize}
U$_{FFDU}$ = m $\cdot$ ($\sqrt[2]{2}$ - 1)\\ Fattore di approssimazione: 1.67. Poiché richiede di ordinare i task, comunque non è on-line.
\subsubsection{RM-FF}
Una variante di RMFF, che non effettua l'ordinamento dei task prima dell'allocazione:
\begin{itemize}
\item ordina arbitrariamente i processori: P${1}$,...
\item assegna ciascun task T$_{i}$ al primo processore P$_{j}$ tale che l'insieme dei task già assegnati a P$_{j}$ insieme a T$_{i}$ risulta ancora schedulabile secondo RM
\end{itemize}
U$_{RM-FF}$ = m $\cdot$ ($\sqrt[2]{2}$ - 1)\\ Fattore di approssimazione: 2.33.\\ A differenza di RMFF, RM-FF può essere usato on-line.
\subsubsection{EDF-FF}
Lo stesso algoritmo di RM-FF, ma schedulo il singolo processore con EDF:
\begin{itemize}
\item ordina arbitrariamente i processori: P${1}$,...
\item assegna ciascun task T$_{i}$ al primo processore P$_{j}$ tale che l'insieme dei task già assegnati a P$_{j}$ insieme a T$_{i}$ risulta ancora schedulabile secondo EDF
\end{itemize}
U$_{EDF-FF}$ = $\frac{\beta \cdot m + 1}{\beta + 1}$, $\beta$ = $\lfloor \frac{1}{\underset{k}{max}\frac{e_k}{p_k}}\rfloor$.\\ Fattore di approssimazione: 1.7 (meno del doppio del n° processori ottimali). È un algoritmo ottimale fra tutti gi algoritmi ottimali:\\ per $\beta$ = 1 $\Rightarrow$ U$_{EDF-FF}$ = $\frac{(m + 1}{2}$, ovvero nel caso peggiore ho il limite superiore nel caso in cui c'è un task di dimensione 1. Posso convivere con l'effetto Dhall, pagando processori in più. Se $\beta \rightarrow \infty$ $\Rightarrow$ U$_{EDF-FF}$ $\rightarrow$ m, per task di dimensioni infinitesima e quindi schedulabili in maniera fluida, l'algoritmo riesce a raggiungere il 100\% di utilizzazione dei processori del sistema.
\end{document}